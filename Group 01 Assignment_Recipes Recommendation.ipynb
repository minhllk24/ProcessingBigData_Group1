{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa07a252-122a-4926-87f6-2e428cc1151d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "# Import module\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, split, regexp_extract\n",
    "# Import for typecasting columns\n",
    "from pyspark.sql.types import IntegerType,BooleanType,DateType,FloatType,StringType\n",
    "from pyspark.sql.types import ArrayType\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ca41ba-f7a0-47d5-bd01-a7a0652609db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"RecipeRecommender\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04ac9880-0ec7-434d-ac8f-5b2a8939c227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Task 1**: Read the Data\n",
    "- Read RAW_recipes_cleaned.csv from the provided link.\n",
    "- Ensure all fields have the correct data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09a0a93e-03a4-43c8-bfa8-99eccd5119d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Task 1: Read the Data\n",
    "Raw_Recipe_Data = (spark.read.csv(\"dbfs:/FileStore/RAW_recipes_cleaned.csv\", header=True,inferSchema=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08bf90d2-ac75-43a9-bf65-78f32477fd2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Show schema\n",
    "Raw_Recipe_Data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad85cf6a-cd1b-4580-a13a-436d48624655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Show the first 5 rows of data\n",
    "# Raw_Recipe_Data.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "630bfa13-6640-48b1-96c1-124ed3db39cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Task 2**: Extract Nutrition Features\n",
    "The nutrition column is currently read as a string. Extract the seven individual nutrition values from each row and create separate columns:\n",
    "- calories\n",
    "- total_fat_PDV\n",
    "- sugar_PDV\n",
    "- sodium_PDV\n",
    "- protein_PDV\n",
    "- saturated_fat_PDV\n",
    "- carbohydrates_PDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01f9858e-9f72-47ae-8130-6598b5b4304a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# String operations to remove square brakets\n",
    "Raw_Recipe_Data.select('nutrition').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567215c0-40cb-4662-b417-f5c032b82c69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List of nutrition columns\n",
    "\n",
    "Nutrition_Col_Names = ['calories',\n",
    "                          'total_fat_PDV',\n",
    "                          'sugar_PDV',\n",
    "                          'sodium_PDV',\n",
    "                          'protein_PDV',\n",
    "                          'saturated_fat_PDV',\n",
    "                          'carbohydrates_PDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e44bf18-b92e-4f6d-9d9b-e4505e8446b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# STEP 2.1 string operations to remove square brakets in 'nutrition' column\n",
    "Raw_Recipe_Data = (Raw_Recipe_Data\n",
    "                  .withColumn('nutrition',(F.regexp_replace(\"nutrition\",\"[\\[\\]]\",\"\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fff4d0e3-60ef-4b4f-b9b2-c1156aaabb49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task 02 Cell 2 out of 3\n",
    "# STEP 2.2 - split the neutrition string into seven individial values. \n",
    "# Create an object to split the nutrition column\n",
    "\n",
    "import pyspark\n",
    "\n",
    "Nutrition_Col_Split = pyspark.sql.functions.split(Raw_Recipe_Data['nutrition'],',')\n",
    "for col_index, col_name in enumerate(Nutrition_Col_Names):\n",
    "    Raw_Recipe_Data = (Raw_Recipe_Data.withColumn(col_name, Nutrition_Col_Split.getItem(col_index).cast(\"float\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63c55ce5-af49-4b45-baf8-0dc14c49e450",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Test cases for task 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b816cf9a-34f3-407b-8a00-854e3a77120e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert Raw_Recipe_Data.schema[\"carbohydrates_PDV\"].dataType == FloatType(), \"Recheck your typecasting\"\n",
    "assert Raw_Recipe_Data.collect()[123432][14] == 62.0, \"The columns have not been split correctly.\"\n",
    "assert Raw_Recipe_Data.collect()[10000][12] == 60.400001525878906, \"The columns have not been split correctly.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "532e05ba-8ed1-44d8-97fb-70dc1a1f4650",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 3: Standardize Nutrition Values\n",
    "Standardize the nutrition values to a per 100 calorie basis to account for serving size variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb6ed987-a4b7-472d-a868-ca5420e1578d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task 03 Cell 1 out of 1\n",
    "\n",
    "for nutrition_col in Nutrition_Col_Names:# loop over each of the newly created nutrition columns \n",
    "    if nutrition_col != \"calories\":\n",
    "        # the calories column should not be a part of the transformation exercise\n",
    "        # following code will name the new columns \n",
    "        nutrition_per_100_cal_col = (nutrition_col\n",
    "                                 .replace('_PDV','')\n",
    "                                 +'_per_100_cal')\n",
    "        Raw_Recipe_Data = Raw_Recipe_Data.withColumn(nutrition_per_100_cal_col,\n",
    "                                               Raw_Recipe_Data[nutrition_col]*100/Raw_Recipe_Data[\"calories\"]\n",
    "                                                # pyspark code to recreate the intended transformation \n",
    "                                                  )\n",
    "        \n",
    "        # You might end up adding nulls to the data because of our intended transformation. \n",
    "        # Perform a fill na operation to fill all the nulls with 0s. \n",
    "        # You must limit the scope of the fill na to the current column only. \n",
    "        \n",
    "        Raw_Recipe_Data = Raw_Recipe_Data.fillna(value=0,subset=[nutrition_per_100_cal_col]) \n",
    "        # pyspark code to fill nulls with 0 in only the current nutrition_per_100_cal_col            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b164bd2b-ae47-4b93-ac6e-f1a85620ce42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Raw_Recipe_Data.toPandas().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff8724a5-bef9-4e07-90f9-e5b2ca18330d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 4: Convert Tags to Array\n",
    "The tags column is currently read as a string. Convert it to an array of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62eb9ad1-694a-4bee-b98f-537f568520a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task 04 Cell 1 out of 1\n",
    "Raw_Recipe_Data = (Raw_Recipe_Data\n",
    "                  .withColumn('tags', F.regexp_replace(\"tags\",\"[\\\\[\\\\]\\\\']\",\"\")\n",
    "                             )\n",
    "                  .withColumn('tags', F.split(\"tags\",\", \")\n",
    "                             )\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0be481e3-3c36-4e5a-bc07-f28004255fd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Raw_Recipe_Data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da285ef4-05da-416e-abc5-4868fdcef37c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Raw_Recipe_Data.schema[\"tags\"].dataType == ArrayType(StringType(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d36b9cd7-6f0c-4a42-b585-17fa59b13c87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Raw_Recipe_Data.toPandas().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd4241b9-490c-4154-9776-4eb462e382df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 5: Read and Join Interaction Data\n",
    "- Read RAW_interactions_cleaned.csv from the provided link.\n",
    "- Join this interaction data with the recipe data using the appropriate key. The resulting dataframe should contain all interactions with corresponding recipe information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "407c160d-fb71-48ac-bcf5-92a3cbf57a44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Raw_Ratings_Data = (spark.read.csv('dbfs:/FileStore/RAW_interactions_cleaned.csv', \n",
    "                                 header=True, \n",
    "                                 inferSchema= True)\n",
    "                  .withColumn(\"review_date\",  F.col(\"date\"))\n",
    "                  .drop(F.col(\"date\"))\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d020d0-bbd2-473c-ae54-333096c65402",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Raw_Ratings_Data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "561a788a-6f71-4020-aae5-70b007a08e6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert Raw_Ratings_Data.count() == 1132367, \"There is a mistake in reading the data.\"\n",
    "assert len(Raw_Ratings_Data.columns) == 5, \"There is a mistake in reading the data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b35c5115-8f9b-44e9-9249-add7efafd16d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Raw_Ratings_Data.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bdadb5b-b87d-4459-9b9d-ffd4390b825f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task 05 Cell 1 out of 1\n",
    "interaction_level_df = Raw_Ratings_Data.join(Raw_Recipe_Data,Raw_Ratings_Data.recipe_id == Raw_Recipe_Data.id,\"inner\")\n",
    "                                           # add the key on which the join should happen\n",
    "                                           # mention the type of join expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b301824d-55a7-45d2-9f8a-ec3b2a149591",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Test cases for Task 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36713182-7437-44db-88a8-64672dbf4ca5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert (interaction_level_df.count() ,len(interaction_level_df.columns)) == (1132367, 30), \"The type of join is incorrect\"\n",
    "\n",
    "lst1 = Raw_Ratings_Data.select('recipe_id').collect()\n",
    "lst2 = Raw_Recipe_Data.select('id').collect()\n",
    "exclusive_set = set(lst1)-set(lst2)\n",
    "\n",
    "assert len(exclusive_set) == 0, \"There is a mistake in reading one of the two data files.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2acd57d4-7e10-4816-b4d0-1a66b741f2df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 6: Create Time-Based Features\n",
    "Create features that capture the time elapsed between a review date and the recipe's submission date. Use the date (from interactions data) and submitted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c99b33e-8951-496a-99ee-a143bb5a5515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn('days_since_submission_on_review_date',F.datediff(\"review_date\",\"submitted\")\n",
    "                                     # Pyspark function to find the number of days between two dates              \n",
    "                                   )\n",
    "                        .withColumn('months_since_submission_on_review_date',F.months_between(\"review_date\",\"submitted\")\n",
    "                                     # Pyspark function to find the number of months between two dates          \n",
    "                                   )\n",
    "                        .withColumn('years_since_submission_on_review_date',F.months_between(\"review_date\",\"submitted\")/12\n",
    "                                     # Pyspark function to find the number of months between two dates / 12          \n",
    "                                   )\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ebf67fe-3f0a-4685-9a13-3049b32ecaec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Test cases for Task 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cab96bb7-085b-4e10-963c-c1e91f4f8ed6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "assert interaction_level_df.schema[\"days_since_submission_on_review_date\"].dataType == IntegerType()\n",
    "\n",
    "assert (interaction_level_df.filter((interaction_level_df.user_id == 428885) & (interaction_level_df.recipe_id == 335241))\n",
    "                            .select('days_since_submission_on_review_date').collect()[0][0]) == 77\n",
    "assert (interaction_level_df.filter((interaction_level_df.user_id == 2025676) & (interaction_level_df.recipe_id == 94265))\n",
    "                            .select('months_since_submission_on_review_date').collect()[0][0]) == 153.22580645\n",
    "assert (interaction_level_df.filter((interaction_level_df.user_id == 338588) & (interaction_level_df.recipe_id == 21859))\n",
    "                            .select('years_since_submission_on_review_date').collect()[0][0]) == 4.564516129166667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dbf1bc2-bcc4-49ec-bf18-ac2f3fc3cf8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bad810f-1d5e-4d58-a719-8fee7a7c8cbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# interaction_level_df.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b16e5bb9-fbbb-45e5-81cc-da8c1b9a7a88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the data we have created so far in a parquet file\n",
    "interaction_level_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bcdfc66-6d86-4595-b590-3617d79bbc5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert (interaction_level_df.count() ,len(interaction_level_df.columns) ) == (1132367, 33)\n",
    "(interaction_level_df.count() ,len(interaction_level_df.columns) ) == (1132367, 33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af7dbb8d-34e2-4e46-9f49-1981f9f2303c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Write the raw_recipes_df\n",
    "## create a folder named data in you current directry before running this. \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "interaction_level_df.write.parquet(\"dbfs:/FileStore/interaction_level_df\") # Modify the path as you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "130c6e06-b530-4e6d-8de7-21e35062c7bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdf87b0f-fbb1-4fd0-93ee-e4dbc2a460e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initial Setup\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cad701fa-659d-4c79-a4fb-56bdad5eccbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this everytime you create a new spark instance. \n",
    "\n",
    "# Use %pip to install the required libraries\n",
    "%pip install plotly==5.5.0\n",
    "%pip install pandas==0.25.1\n",
    "%pip install numpy==1.14.5\n",
    "%pip install matplotlib==3.1.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2398b92d-ad7d-46d6-9e01-c94a0f0e4bb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import for typecasting columns\n",
    "from pyspark.sql.types import IntegerType,BooleanType,DateType,FloatType,StringType\n",
    "from pyspark.sql.types import ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11f7f0ca-e66c-4083-bbc5-e3fb262c7e35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defining Custom Functions\n",
    "def get_quantiles(df, col_name, quantiles_list = [0.01, 0.25, 0.5, 0.75, 0.99]):\n",
    "    \"\"\"\n",
    "    Takes a numerical column and returns column values at requested quantiles\n",
    "\n",
    "    Inputs \n",
    "    Argument 1: Dataframe\n",
    "    Argument 2: Name of the column\n",
    "    Argument 3: A list of quantiles you want to find. Default value [0.01, 0.25, 0.5, 0.75, 0.99]\n",
    "\n",
    "    Output \n",
    "    Returns a dictionary with quantiles as keys and column quantile values as values \n",
    "    \"\"\"\n",
    "    # Get min, max and quantile values for given column\n",
    "    min_val = df.agg(F.min(col_name)).first()[0]\n",
    "    max_val = df.agg(F.max(col_name)).first()[0]\n",
    "    quantiles_vals = df.approxQuantile(col_name,\n",
    "                                       quantiles_list,\n",
    "                                       0)\n",
    "  \n",
    "    # Store min, quantiles and max in output dict, sequentially\n",
    "    quantiles_dict = {0.0:min_val}\n",
    "    quantiles_dict.update(dict(zip(quantiles_list, quantiles_vals)))\n",
    "    quantiles_dict.update({1.0:max_val})\n",
    "    return(quantiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dab5af8-9692-4206-9062-c95a7059839d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_bucketwise_statistics(summary, bucketizer):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and a bucketizer object and plots the summary statistics for each bucket in the dataframe. \n",
    "  \n",
    "    Inputs\n",
    "    Argument 1: Pandas dataframe obtained from bucket_col_print_summary function \n",
    "    Argument 2: Bucketizer object obtained from bucket_col_print_summary function\n",
    "  \n",
    "    Output\n",
    "    Displays a plot of bucketwise average ratings and number of ratings for a parameter.   \n",
    "    \"\"\"\n",
    "    # Creating bucket labels from splits\n",
    "    classlist = bucketizer.getSplits()\n",
    "    number_of_classes = len(classlist) - 1\n",
    "\n",
    "    class_labels = []\n",
    "    hover_labels = []\n",
    "    for i in range(number_of_classes):\n",
    "        hover_labels.append(str(classlist[i]) + \"-\" + str(classlist[i+1]) + \" (Bucket name: \" + str(int(i)) + \")\")\n",
    "        class_labels.append(str(classlist[i]) + \"-\" + str(classlist[i+1]))\n",
    "  \n",
    "    summary[\"Scaled_number\"] = (summary[\"n_ratings\"] - summary[\"n_ratings\"].min()) / (summary[\"n_ratings\"].max() - summary[\"n_ratings\"].min()) + 1.5\n",
    "    summary['Bucket_Names'] = class_labels\n",
    "  \n",
    "    # Making the plot\n",
    "    x = summary[\"Bucket_Names\"]\n",
    "    y1 = summary[\"avg_rating\"]\n",
    "    y2 = summary[\"n_ratings\"]\n",
    "    err = summary[\"stddev_rating\"]  \n",
    "\n",
    "    # Setting up the figure\n",
    "    plt.rcParams[\"figure.figsize\"] = [summary.shape[0] + 2, 6.0]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Bars with dark blue color\n",
    "    bar = ax1.bar(x, y1, color=\"#00008B\")\n",
    "    ax1.errorbar(x, y1, yerr=err, fmt=\"o\", color=\"#FFD700\")  # Error bars in dark yellow\n",
    "    ax1.set(ylim=(0, 7))\n",
    "  \n",
    "    # Add labels above the bars\n",
    "    def barlabel(x_list, y_list):\n",
    "        for i in range(len(x_list)):\n",
    "            ax1.text(i, y_list[i] + 0.2, y_list[i], ha='center',\n",
    "                     fontdict=dict(size=10),\n",
    "                     bbox=dict(facecolor='#00008B', alpha=0.2))\n",
    "    barlabel(summary[\"Bucket_Names\"].tolist(), summary[\"avg_rating\"].round(2).tolist())\n",
    "  \n",
    "    # Scatter plot with dark yellow color\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.scatter(x, y2, s=summary[\"Scaled_number\"] * 500, c=\"#FFD700\")  \n",
    "    ax2.set(ylim=(0, summary[\"n_ratings\"].max() * 1.15))\n",
    "\n",
    "    # Add labels above the scatter points\n",
    "    def scatterlabel(x_list, y_list):\n",
    "        for i in range(len(x_list)):\n",
    "            ax2.text(i, y_list[i] + 15000, y_list[i], ha='center',\n",
    "                     fontdict=dict(size=10),\n",
    "                     bbox=dict(facecolor='#FFD700', alpha=0.5))\n",
    "    scatterlabel(summary[\"Bucket_Names\"].tolist(), summary[\"n_ratings\"].tolist())\n",
    "  \n",
    "    # Giving labels to the axes\n",
    "    ax1.set_xlabel(bucketizer.getOutputCol(), fontdict=dict(size=14)) \n",
    "    ax1.set_ylabel(\"Average Ratings\", fontdict=dict(size=14))\n",
    "  \n",
    "    # Secondary y-axis label\n",
    "    ax2.set_ylabel('Number of Ratings', fontdict=dict(size=14))\n",
    "  \n",
    "    # Plot title\n",
    "    plt.title('Average ratings for each bucket and the quantity of ratings for \\n' + bucketizer.getInputCol(), \n",
    "              fontdict=dict(size=14))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c7b12f8-3540-4139-9028-864419b78aa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def bucket_col_print_summary(df, splits, inputCol, outputCol):\n",
    "    \"\"\"\n",
    "    Given a numerical column in a data frame, adds a bucketized version of the column to the data frame, according to splits provided.\n",
    "    Also prints a summary of ratings seen in each bucket made.\n",
    "\n",
    "    Inputs \n",
    "    Argument 1: Data Frame \n",
    "    Argument 2: Values at which the column will be split\n",
    "    Argument 3: Name of the input column (numerical column)\n",
    "    Argument 4: Name of the output column (bucketized numerical column)\n",
    "\n",
    "    Output: \n",
    "    1) New dataframe with the output column added\n",
    "    2) Bucketizer object trained from the input column \n",
    "    3) Pandas dataframe with summary statistics for ratings seen in buckets of the output column\n",
    "    Also plots summary statistics for ratings seen in buckets of the output column\n",
    "    \"\"\"\n",
    "\n",
    "    # Dropping bucket if it already exists\n",
    "    if outputCol in df.columns:\n",
    "        df = df.drop(outputCol)\n",
    "\n",
    "    # Training bucketizer\n",
    "    bucketizer = Bucketizer(splits = splits,\n",
    "                            inputCol  = inputCol,\n",
    "                            outputCol = outputCol)\n",
    "    \n",
    "    df = bucketizer.setHandleInvalid(\"keep\").transform(df)\n",
    "\n",
    "    # Printing meta information on buckets created\n",
    "    print(\"Added bucketized column {}\".format(outputCol))\n",
    "    print(\"\")\n",
    "    print(\"Bucketing done for split definition: {}\".format(splits))\n",
    "    print(\"\")  \n",
    "    print(\"Printing summary statistics for ratings in buckets below:\")\n",
    "\n",
    "    # Creating a summary statistics dataframe and passing it to the plotting function\n",
    "    summary =  (df\n",
    "                .groupBy(outputCol)\n",
    "                .agg(F.avg('rating').alias('avg_rating'),\n",
    "                     F.stddev('rating').alias('stddev_rating'),\n",
    "                     F.count('rating').alias('n_ratings'))\n",
    "                .sort(outputCol)\n",
    "                .toPandas())\n",
    "  \n",
    "    plot_bucketwise_statistics(summary,bucketizer)\n",
    "  \n",
    "    return df, bucketizer, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f24f9e3-8246-4227-9245-8210debae501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_column_distribution_summary(df, col_name):\n",
    "    \"\"\"\n",
    "    Takes a column in a data frame and prints the summary statistics (average, standard deviation, count and distinct count) for all unique values in that column.\n",
    "  \n",
    "    Inputs \n",
    "    Argument 1: Dataframe \n",
    "    Argument 2: Name of the column\n",
    "  \n",
    "    Output\n",
    "    Returns nothing \n",
    "    Prints a Dataframe with summary statistics\n",
    "    \"\"\"\n",
    "    print(df\n",
    "          .groupBy(col_name)\n",
    "          .agg(F.avg('rating').alias('avg_rating'),\n",
    "               F.stddev('rating').alias('stddev_rating'),\n",
    "               F.count('rating').alias('n_ratings'),\n",
    "               F.countDistinct('id').alias('n_recipes'))\n",
    "          .sort(F.col(col_name).asc())\n",
    "          .show(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd606399-a39c-4132-acbb-8cdffaead50c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_n_items_satisfying_condition (df, condition, aggregation_level = \"recipe\"):\n",
    "    \"\"\"\n",
    "    Given a condition, find the number of recipes / reviews that match the condition.\n",
    "    Also calculates the percentage of such recipes / reviews as a percentage of all recipes / reviews.\n",
    "  \n",
    "    Inputs \n",
    "    Argument 1: Dataframe \n",
    "    Argument 2: Logical expression describing a condition, string type. eg: \"minutes == 0\"\n",
    "    Argument 3: Aggregation level for determining \"items\", either  \"recipe\" or \"review\". Default value == \"recipe\"\n",
    "  \n",
    "    Output: Returns no object.\n",
    "    Prints the following:\n",
    "    1) Number of recipes / reviews that satisfy the condition\n",
    "    2) Total number of recipes / reviews in the dataframe\n",
    "    3) Percentage of recipes / reviews that satisfy the condition\n",
    "    \"\"\"\n",
    "    # Find out num rows satisfying the condition\n",
    "    if aggregation_level == \"recipe\": \n",
    "        number_of_rows_satisfying_condition = (df\n",
    "                                             .filter(condition)\n",
    "                                             .agg(F.countDistinct(\"id\"))).first()[0]\n",
    "      \n",
    "        n_rows_total = (df.agg(F.countDistinct(\"id\"))).first()[0]\n",
    "    if aggregation_level == \"review\":\n",
    "        number_of_rows_satisfying_condition = (df\n",
    "                                             .filter(condition)\n",
    "                                             .agg(F.countDistinct(\"id\",\"user_id\"))).first()[0]\n",
    "        n_rows_total = (df.agg(F.countDistinct(\"id\",\"user_id\"))).first()[0]\n",
    "  \n",
    "    # Find out % rows satisfying the conditon and print a properly formatted output\n",
    "    perc_rows = round(number_of_rows_satisfying_condition * 100/ n_rows_total, 2)\n",
    "    print('Condition String                   : \"{}\"'.format(condition))\n",
    "    print(\"Num {}s Satisfying Condition   : {} [{}%]\".format(aggregation_level.title(), number_of_rows_satisfying_condition, perc_rows))\n",
    "    print(\"Total Num {}s                  : {}\".format(aggregation_level.title(), n_rows_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77cb869e-6d76-4ccd-88ae-99c95b8a0559",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "# Read interaction_level_df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56c1b0c1-6372-42b6-b9a5-08560759d987",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df_processed = spark.read.parquet(\"dbfs:/FileStore/interaction_level_df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2388a6e9-e883-441c-bd46-9d126a4c7638",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert interaction_level_df.count() == 1132367, \"There is a mistake in reading the data.\"\n",
    "assert len(interaction_level_df.columns) == 33, \"There is a mistake in reading the data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "463f34d5-0f87-4d51-84ad-49d6597f26e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "862b26bd-a380-4bd9-bbc8-9077cb50c5d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.toPandas().head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fc1031f-c3a1-479f-b2d4-1df8afbcc5a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 7: Process Numerical Columns (Optional)\n",
    "- Introduce non-linearity to numerical columns by converting them into categorical columns using binning (percentile-based bucketing).\n",
    "- Columns to consider:\n",
    "> - years_since_submission_on_review_date\n",
    "> - minutes\n",
    "> - calories\n",
    "> - total_fat_PDV\n",
    "> - sugar_PDV\n",
    "> - sodium_PDV\n",
    "> - protein_PDV\n",
    "> - saturated_fat_PDV\n",
    "> - carbohydrates_PDV\n",
    "- Analyze the average rating for each bucket to determine the usefulness of the bucketed column.\n",
    "- Handle any data inconsistencies or edge cases (e.g., reviews before submission date) appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8409449b-5c20-4d89-be55-1e7f2be1b333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Bucketing and Cleaning Numerical Features\n",
    "\n",
    "# 1. years_since_submission_on_review_date\n",
    "\n",
    "# [Review Time Since Submission]\n",
    "\n",
    "# Recipes more than 6 years old are rated low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7c25ede-c3ee-4212-9515-1399807dc9ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles(df = interaction_level_df,\n",
    "             col_name = \"years_since_submission_on_review_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "843ee242-a69a-4578-967d-b1a7fefadf14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "get_n_items_satisfying_condition(df = interaction_level_df,\n",
    "                                 condition= 'years_since_submission_on_review_date < 0',\n",
    "                                 aggregation_level= \"review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39f78cf2-d852-48d7-a1b3-3c4bede45196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Only keep interactions with review dates >= recipe submission date\n",
    "\n",
    "interaction_level_df = (interaction_level_df\n",
    "                        .filter('years_since_submission_on_review_date >= 0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10ec68fb-491c-4656-bdcb-f04844e4702d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "splits = [ 0, 1, 3, 6, float('Inf')]\n",
    "inputCol  = \"years_since_submission_on_review_date\"\n",
    "outputCol = \"years_since_submission_on_review_date_bucket\"\n",
    "\n",
    "(interaction_level_df, submission_time_bucketizer, submission_time_pandas_df) = bucket_col_print_summary(df = interaction_level_df,\n",
    "                                                                              splits = splits,\n",
    "                                                                              inputCol  = inputCol,\n",
    "                                                                              outputCol = outputCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93a12058-f717-41e0-b5d5-3a194cd1a372",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%matplot plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa68a16f-1f38-4551-a00e-963deafcb053",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. minutes\n",
    "# [prep time]\n",
    "\n",
    "# Somewhat relevant\n",
    "# Low prep time is preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44ed743a-2ce0-46bb-875c-730ca13db24d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles(df = interaction_level_df,\n",
    "              col_name = \"minutes\",\n",
    "              quantiles_list=[0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d0fb1a5-d74c-4d15-bc0e-5b28f4774793",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Capping prep time at 930 minutes\n",
    "\n",
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn(\"minutes\",\n",
    "                                    F.when(interaction_level_df[\"minutes\"] > 930, 930)\n",
    "                                     .otherwise(interaction_level_df[\"minutes\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d4827a7-b93b-42b0-9ed9-590f4d36665d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# let's look at some examples with 1 step only to see if this makes sense\n",
    "\n",
    "interaction_level_df.filter('minutes == 0 and n_steps == 1').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a84957f0-5c68-4751-81e2-5c8d14231284",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_n_items_satisfying_condition(df = interaction_level_df,\n",
    "                                 condition = 'minutes == 0',\n",
    "                                 aggregation_level = \"recipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3740548-cec2-4371-936d-7f2d16ced886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove recipes with cook time zero\n",
    "\n",
    "interaction_level_df = interaction_level_df.filter(\"minutes > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cad63a64-340c-4fb0-b592-a40082ad6196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_n_items_satisfying_condition(df = interaction_level_df,\n",
    "                                 condition = 'minutes == 0',\n",
    "                                 aggregation_level = \"recipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2c86c43-ee5f-4d2a-aa5e-0e7c294378c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "splits = [0, 15, 30, 60, float('Inf')]\n",
    "inputCol  = \"minutes\"\n",
    "outputCol = \"prep_time_bucket\"\n",
    "\n",
    "(interaction_level_df, prep_time_bucketizer, prep_time_summary_pandas_df) = bucket_col_print_summary(df = interaction_level_df,\n",
    "                                                                              splits = splits,\n",
    "                                                                              inputCol  = inputCol,\n",
    "                                                                              outputCol = outputCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58bdc561-2a11-4a22-ba66-e26a63bc84ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%matplot plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02c22f03-ac9b-4563-bfb4-42e047d38584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. n_steps\n",
    "# Clearly relevant\n",
    "\n",
    "# Recipes with less than 2 steps are rated high\n",
    "\n",
    "# Recipes with more than 29 steps are rated very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17edc71a-ac16-42d7-9ee9-e57bb885d2e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles(df = interaction_level_df,\n",
    "              col_name = \"n_steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dcdc68c-8f91-44e1-a852-a8620e30c328",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.filter('n_steps == 0').show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a82c1092-83f4-4d91-93a8-46e752b3edeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_n_items_satisfying_condition(df = interaction_level_df,\n",
    "                                 condition = 'n_steps == 0',\n",
    "                                 aggregation_level = \"recipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c9b5201-a581-4829-8185-5a9dc35f73d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove recipes with n_steps zero\n",
    "\n",
    "interaction_level_df = interaction_level_df.filter(\"n_steps > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ad016b8-7f1d-4fd0-b529-7c7531ca19f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "splits = [0, 2, 6, 8, 12, 29, float('Inf')]\n",
    "inputCol  = \"n_steps\"\n",
    "outputCol = \"n_steps_bucket\"\n",
    "\n",
    "(interaction_level_df, n_steps_bucketizer, n_steps_pandas_df) = bucket_col_print_summary(df = interaction_level_df,\n",
    "                                                                              splits = splits,\n",
    "                                                                              inputCol  = inputCol,\n",
    "                                                                              outputCol = outputCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a837bbf1-3063-44c4-b6b4-36ffcbb86f14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%matplot plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a2786ba-4c14-4a29-9bd5-f49e89582ec1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. n_ingredients\n",
    "\n",
    "# Not relevant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e099a5f9-bbe6-424f-a098-ea38818bc42b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles(df = interaction_level_df,\n",
    "              col_name = \"n_ingredients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "911e710d-09fa-4707-9ab4-6e43101b836d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "splits = [0, 6, 9, 11, float('Inf')]\n",
    "inputCol  = \"n_ingredients\"\n",
    "outputCol = \"n_ingredients_bucket\"\n",
    "\n",
    "(interaction_level_df, n_ingredients_bucketizer, n_ingredients_pandas_df) = bucket_col_print_summary(df = interaction_level_df,\n",
    "                                                                              splits = splits,\n",
    "                                                                              inputCol  = inputCol,\n",
    "                                                                              outputCol = outputCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ff93642-78cb-4ac6-b928-af84aba7c69b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%matplot plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79497146-9505-4b75-bec7-99748552dd2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. nutrition columns\n",
    "# calories - Calories per serving seems irrelevant\n",
    "# fat (per 100 cal) - Calories per serving seems irrelevant\n",
    "# sugar (per 100 cal) - Calories per serving seems irrelevant\n",
    "# sodium (per 100 cal) - Calories per serving seems irrelevant\n",
    "# protein (per 100 cal) - Calories per serving seems irrelevant\n",
    "# sat. fat (per 100 cal) - Calories per serving seems irrelevant\n",
    "# carbs (per 100 cal) - Calories per serving seems irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b25629a6-144c-42ff-b433-d37ac82473e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8f54c94-ad5a-4d87-b56f-89c8e45cea12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nutrition_cols = ['calories', \n",
    "                  'total_fat_PDV', \n",
    "                  'sugar_PDV', \n",
    "                  'sodium_PDV', \n",
    "                  'protein_PDV', \n",
    "                  'saturated_fat_PDV', \n",
    "                  'carbohydrates_PDV', \n",
    "                  'total_fat_per_100_cal', \n",
    "                  'sugar_per_100_cal', \n",
    "                  'sodium_per_100_cal', \n",
    "                  'protein_per_100_cal', \n",
    "                  'saturated_fat_per_100_cal', \n",
    "                  'carbohydrates_per_100_cal']\n",
    "\n",
    "quantiles_list = [0.00, 0.05, 0.25, 0.5, 0.75, 0.95, 1.00]\n",
    "nutrition_col_quantiles = pd.DataFrame(index = quantiles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d32d24a1-ccfa-4ea6-bc41-dee24b4a4006",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for col in nutrition_cols:\n",
    "    nutrition_col_quantiles[col] = (get_quantiles(df = interaction_level_df,\n",
    "                                                col_name = col,\n",
    "                                                quantiles_list=quantiles_list)\n",
    "                                  .values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bbdfb1c-28ce-446e-a552-718c171580f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nutrition_col_quantile_summary = pd.DataFrame(index = [\"0.00-0.25\", \"0.25-0.50\", \"0.50-0.75\", \"0.75-0.95\", \"0.95 - 1.00\"])\n",
    "\n",
    "for col in nutrition_cols:\n",
    "    splits = ([0]\n",
    "            + list(nutrition_col_quantiles.loc[[0.25, 0.5, 0.75, 0.95], col].round())\n",
    "            + [float('Inf')])\n",
    "    inputCol  = col\n",
    "    outputCol = col+\"_bucket\"\n",
    "\n",
    "    if outputCol in interaction_level_df.columns:\n",
    "        interaction_level_df = interaction_level_df.drop(outputCol)\n",
    "\n",
    "  # Training bucketizer\n",
    "    bucketizer = Bucketizer(splits = splits,\n",
    "                          inputCol  = inputCol,\n",
    "                          outputCol = outputCol)\n",
    "  \n",
    "    interaction_level_df = bucketizer.setHandleInvalid(\"keep\").transform(interaction_level_df)\n",
    "  \n",
    "    nutrition_col_quantile_summary.loc[:, col] = (interaction_level_df\n",
    "                                                .groupBy(outputCol)\n",
    "                                                .agg(F.avg('rating').alias('avg_rating'))\n",
    "                                                .sort(outputCol)\n",
    "                                                .select('avg_rating').toPandas().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8c37d20-77a2-4f64-a6dc-cb73f1fa7a54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set the max columns to none\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7f69d39-a741-4488-9ca3-e93d0a898dab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nutrition_col_quantile_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bbf1304-830d-46aa-934b-d1c59d56b135",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 8: Create User-Level Features (Optional)\n",
    "- Create features that capture user preferences and rating tendencies:\n",
    "> - user_avg_rating\n",
    "> - user_avg_n_ratings\n",
    "> - user_avg_years_betwn_review_and_submission\n",
    "> - user_avg_prep_time_recipes_reviewed\n",
    "> - user_avg_n_steps_recipes_reviewed\n",
    "> - user_avg_n_ingredients_recipes_reviewed\n",
    "> - user_avg_years_betwn_review_and_submission_high_ratings\n",
    "> - user_avg_calories_recipes_reviewed\n",
    "> - user_avg_total_fat_per_100_cal_recipes_reviewed\n",
    "> - user_avg_sugar_per_100_cal_recipes_reviewed\n",
    "> - user_avg_sodium_per_100_cal_recipes_reviewed\n",
    "> - user_avg_protein_per_100_cal_recipes_reviewed\n",
    "> - user_avg_saturated_fat_per_100_cal_recipes_reviewed\n",
    "> - user_avg_carbohydrates_per_100_cal_recipes_reviewed\n",
    "> - user_avg_prep_time_recipes_reviewed_high_ratings\n",
    "> - user_avg_n_steps_recipes_reviewed_high_ratings\n",
    "> - user_avg_n_ingredients_recipes_reviewed_high_ratings\n",
    "- \"High ratings\" refers to reviews with a rating of 5.\n",
    "- Check for and handle any null values introduced during feature creation.\n",
    "- Consider bucketing these user-level features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b88c0cf-50ff-4cdb-a483-7ea3b86d18c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 03_FEATURE_EXTRACTION_PART\n",
    "\n",
    "# Initial Setup (2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b5cf2f8-4cf4-4fbc-9f24-fe584037725e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d96b84db-1182-412d-9fb0-a7d81ee10e37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe2da961-1fd6-444d-ae5e-0a9334d26277",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this everytime you create a new spark instance. \n",
    "\n",
    "spark.sparkContext.install_pypi_package(\"plotly==5.5.0\")\n",
    "spark.sparkContext.install_pypi_package(\"pandas==0.25.1\")\n",
    "spark.sparkContext.install_pypi_package(\"numpy==1.14.5\")\n",
    "spark.sparkContext.install_pypi_package(\"matplotlib==3.1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89816191-ea7a-4a27-acb3-500b87a7e932",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Import for typecasting columns\n",
    "from pyspark.sql.types import IntegerType,BooleanType,DateType,FloatType,StringType\n",
    "from pyspark.sql.types import ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba8f82c9-b816-4385-aa00-5931db4dd1ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defining Custom Functions (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58436bf6-8b50-4d86-b47c-3233288a38b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_quantiles(df, col_name, quantiles_list = [0.01, 0.25, 0.5, 0.75, 0.99]):\n",
    "    \"\"\"\n",
    "    Takes a numerical column and returns column values at requested quantiles\n",
    "\n",
    "    Inputs \n",
    "    Argument 1: Dataframe\n",
    "    Argument 2: Name of the column\n",
    "    Argument 3: A list of quantiles you want to find. Default value [0.01, 0.25, 0.5, 0.75, 0.99]\n",
    "\n",
    "    Output \n",
    "    Returns a dictionary with quantiles as keys and column quantile values as values \n",
    "    \"\"\"\n",
    "    # Get min, max and quantile values for given column\n",
    "    min_val = df.agg(F.min(col_name)).first()[0]\n",
    "    max_val = df.agg(F.max(col_name)).first()[0]\n",
    "    quantiles_vals = df.approxQuantile(col_name,\n",
    "                                       quantiles_list,\n",
    "                                       0)\n",
    "  \n",
    "    # Store min, quantiles and max in output dict, sequentially\n",
    "    quantiles_dict = {0.0:min_val}\n",
    "    quantiles_dict.update(dict(zip(quantiles_list, quantiles_vals)))\n",
    "    quantiles_dict.update({1.0:max_val})\n",
    "    return(quantiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "221661bd-f419-48f7-a0e6-a44974a27e11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_bucketwise_statistics (summary, bucketizer):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and a bucketizer object and plots the summary statistics for each bucket in the dataframe. \n",
    "  \n",
    "    Inputs\n",
    "    Argument 1: Pandas dataframe obtained from bucket_col_print_summary function \n",
    "    Argument 2: Bucketizer object obtained from bucket_col_print_summary function\n",
    "  \n",
    "    Output\n",
    "    Displays a plot of bucketwise average ratings nunber of ratings of a parameter.   \n",
    "    \"\"\"\n",
    "    # Creating bucket labels from splits\n",
    "    classlist = bucketizer.getSplits()\n",
    "    number_of_classes = len(classlist) - 1\n",
    "\n",
    "    class_labels = []\n",
    "    hover_labels = []\n",
    "    for i in range (number_of_classes):\n",
    "        hover_labels.append(str(classlist[i])+\"-\"+str(classlist[i+1]) +\" (Bucket name: \"+ str(int(i)) +\")\"  )\n",
    "        class_labels.append(str(classlist[i])+\"-\"+str(classlist[i+1]) )\n",
    "  \n",
    "    summary[\"Scaled_number\"] = (summary[\"n_ratings\"]-summary[\"n_ratings\"].min())/(summary[\"n_ratings\"].max()-summary[\"n_ratings\"].min()) + 1.5\n",
    "    summary['Bucket_Names'] = class_labels\n",
    "  \n",
    "    # making plot\n",
    "    x = summary[\"Bucket_Names\"]\n",
    "    y1 = summary[\"avg_rating\"]\n",
    "    y2 = summary[\"n_ratings\"]\n",
    "    err = summary[\"stddev_rating\"]  \n",
    "\n",
    "    # Plot scatter here\n",
    "    plt.rcParams[\"figure.figsize\"] = [summary.shape[0]+2, 6.0]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    bar = ax1.bar(x, y1, color = \"#0000FF\")\n",
    "    ax1.errorbar(x, y1, yerr=err, fmt=\"o\", color=\"#FF0000\")\n",
    "    ax1.set(ylim=(0, 7))\n",
    "  \n",
    "    #ax1.bar_label(bar , fmt='%.2f', label_type='edge')  \n",
    "    def barlabel(x_list,y_list):\n",
    "        for i in range(len(x_list)):\n",
    "            ax1.text(i,y_list[i] + 0.2,y_list[i], ha = 'center',\n",
    "  \t\t\t         fontdict=dict(size=10),\n",
    "  \t\t\t         bbox=dict(facecolor='#00008B', alpha=0.2)         \n",
    "  \t\t\t        )\n",
    "    barlabel(summary[\"Bucket_Names\"].tolist() ,summary[\"avg_rating\"].round(2).tolist())\n",
    "  \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.scatter(x, y2, s=summary[\"Scaled_number\"]*500, c = '#FFA500')  \n",
    "    ax2.set(ylim=(0, summary[\"n_ratings\"].max()*1.15))\n",
    "    def scatterlabel(x_list,y_list):\n",
    "  \t    for i in range(len(x_list)):\n",
    "  \t\t    ax2.text(i,y_list[i] + 15000,y_list[i], ha = 'center',\n",
    "  \t\t\t\t\t fontdict=dict(size=10),\n",
    "                     bbox=dict(facecolor='#418BFA', alpha=0.5)\n",
    "  \t\t\t\t\t)\n",
    "    scatterlabel(summary[\"Bucket_Names\"].tolist() ,summary[\"n_ratings\"].tolist())\n",
    "  \n",
    "    # giving labels to the axises\n",
    "    ax1.set_xlabel(bucketizer.getOutputCol(), fontdict=dict(size=14)) \n",
    "    ax1.set_ylabel(\"Average Ratings\",fontdict=dict(size=14))\n",
    "  \n",
    "    # secondary y-axis label\n",
    "    ax2.set_ylabel('Number of Ratings',fontdict=dict(size=14))\n",
    "  \n",
    "    #plot Title\n",
    "    plt.title('Bucketwise average ratings and number of ratings for \\n'+bucketizer.getInputCol(), \n",
    "              fontdict=dict(size=14))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f76089db-58d2-46a3-b7c2-f1c09182cd65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def bucket_col_print_summary(df, splits, inputCol, outputCol):\n",
    "    \"\"\"\n",
    "    Given a numerical column in a data frame, adds a bucketized version of the column to the data frame, according to splits provided.\n",
    "    Also prints a summary of ratings seen in each bucket made.\n",
    "\n",
    "    Inputs \n",
    "    Argument 1: Data Frame \n",
    "    Argument 2: Values at which the column will be split\n",
    "    Argument 3: Name of the input column (numerical column)\n",
    "    Argument 4: Name of the output column (bucketized numerical column)\n",
    "\n",
    "    Output: \n",
    "    1) New dataframe with the output column added\n",
    "    2) Bucketizer object trained from the input column \n",
    "    3) Pandas dataframe with summary statistics for ratings seen in buckets of the output column\n",
    "    Also plots summary statistics for ratings seen in buckets of the output column\n",
    "    \"\"\"\n",
    "\n",
    "    # Dropping bucket if it already exists\n",
    "    if outputCol in df.columns:\n",
    "        df = df.drop(outputCol)\n",
    "\n",
    "    # Training bucketizer\n",
    "    bucketizer = Bucketizer(splits = splits,\n",
    "                            inputCol  = inputCol,\n",
    "                            outputCol = outputCol)\n",
    "    \n",
    "    df = bucketizer.setHandleInvalid(\"keep\").transform(df)\n",
    "\n",
    "    # Printing meta information on buckets created\n",
    "    print(\"Added bucketized column {}\".format(outputCol))\n",
    "    print(\"\")\n",
    "    print(\"Bucketing done for split definition: {}\".format(splits))\n",
    "    print(\"\")  \n",
    "    print(\"Printing summary statistics for ratings in buckets below:\")\n",
    "\n",
    "    # Creating a summary statistics dataframe and passing it to the plotting function\n",
    "    summary =  (df\n",
    "                .groupBy(outputCol)\n",
    "                .agg(F.avg('rating').alias('avg_rating'),\n",
    "                     F.stddev('rating').alias('stddev_rating'),\n",
    "                     F.count('rating').alias('n_ratings'))\n",
    "                .sort(outputCol)\n",
    "                .toPandas())\n",
    "  \n",
    "    plot_bucketwise_statistics(summary,bucketizer)\n",
    "  \n",
    "    return df, bucketizer, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6bf27bb-3b50-49f9-989f-e3d122d5f248",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_column_distribution_summary(df, col_name):\n",
    "    \"\"\"\n",
    "    Takes a column in a data frame and prints the summary statistics (average, standard deviation, count and distinct count) for all unique values in that column.\n",
    "  \n",
    "    Inputs \n",
    "    Argument 1: Dataframe \n",
    "    Argument 2: Name of the column\n",
    "  \n",
    "    Output\n",
    "    Returns nothing \n",
    "    Prints a Dataframe with summary statistics\n",
    "    \"\"\"\n",
    "    print(df\n",
    "          .groupBy(col_name)\n",
    "          .agg(F.avg('rating').alias('avg_rating'),\n",
    "               F.stddev('rating').alias('stddev_rating'),\n",
    "               F.count('rating').alias('n_ratings'),\n",
    "               F.countDistinct('id').alias('n_recipes'))\n",
    "          .sort(F.col(col_name).asc())\n",
    "          .show(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "015aec82-c34b-4a4e-bc36-69aa74fe2fb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_n_items_satisfying_condition (df, condition, aggregation_level = \"recipe\"):\n",
    "    \"\"\"\n",
    "    Given a condition, find the number of recipes / reviews that match the condition.\n",
    "    Also calculates the percentage of such recipes / reviews as a percentage of all recipes / reviews.\n",
    "  \n",
    "    Inputs \n",
    "    Argument 1: Dataframe \n",
    "    Argument 2: Logical expression describing a condition, string type. eg: \"minutes == 0\"\n",
    "    Argument 3: Aggregation level for determining \"items\", either  \"recipe\" or \"review\". Default value == \"recipe\"\n",
    "  \n",
    "    Output: Returns no object.\n",
    "    Prints the following:\n",
    "    1) Number of recipes / reviews that satisfy the condition\n",
    "    2) Total number of recipes / reviews in the dataframe\n",
    "    3) Percentage of recipes / reviews that satisfy the condition\n",
    "    \"\"\"\n",
    "    # Find out num rows satisfying the condition\n",
    "    if aggregation_level == \"recipe\": \n",
    "        number_of_rows_satisfying_condition = (df\n",
    "                                             .filter(condition)\n",
    "                                             .agg(F.countDistinct(\"id\"))).first()[0]\n",
    "      \n",
    "        n_rows_total = (df.agg(F.countDistinct(\"id\"))).first()[0]\n",
    "    if aggregation_level == \"review\":\n",
    "        number_of_rows_satisfying_condition = (df\n",
    "                                             .filter(condition)\n",
    "                                             .agg(F.countDistinct(\"id\",\"user_id\"))).first()[0]\n",
    "        n_rows_total = (df.agg(F.countDistinct(\"id\",\"user_id\"))).first()[0]\n",
    "  \n",
    "    # Find out % rows satisfying the conditon and print a properly formatted output\n",
    "    perc_rows = round(number_of_rows_satisfying_condition * 100/ n_rows_total, 2)\n",
    "    print('Condition String                   : \"{}\"'.format(condition))\n",
    "    print(\"Number of {}s Satisfying Condition   : {} [{}%]\".format(aggregation_level.title(), number_of_rows_satisfying_condition, perc_rows))\n",
    "    print(\"Total Number of {}s                  : {}\".format(aggregation_level.title(), n_rows_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbc28dfa-055d-4596-9ae6-3a63dfb63dc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_OHE_columns (df, n_name_list):\n",
    "    \"\"\"\n",
    "    Given a list of tags, creates one hot encoded columns for each tag. \n",
    "  \n",
    "    Input\n",
    "    Argument 1: Dataframe in which the function will add the new columns\n",
    "    Argument 2: list of tags\n",
    "  \n",
    "    Output\n",
    "    Prints the names of columns that have been added \n",
    "    Returns the modified dataframe \n",
    "    \"\"\"\n",
    "    for name in n_name_list:\n",
    "        df = (df.withColumn(\"has_tag_\"+name, F.when(F.array_contains(df.tags, name), 1).otherwise(0)))\n",
    "        print (\"added column: has_tag_\"+name)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c81951e4-df1f-4ab3-a1ee-bb3bda997bb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the data (2)\n",
    "\n",
    "# Read interaction_level_df_processed\n",
    "interaction_level_df = spark.read.parquet(\"dbfs:/FileStore/interaction_level_df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f640bf1a-52ec-4589-a12d-63cd6291dc01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Adding user level average features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ea6f494-e6b6-471f-a6a7-bfb355b2e193",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "partition = Window.partitionBy(\"user_id\")\n",
    "\n",
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn(\"user_avg_rating\",\n",
    "                                    F.avg(F.col(\"rating\")).over(partition))\n",
    "                        .withColumn(\"user_n_ratings\",\n",
    "                                    F.count(F.col(\"rating\")).over(partition))\n",
    "                        .withColumn(\"user_avg_years_betwn_review_and_submission\",\n",
    "                                    F.avg(F.col(\"years_since_submission_on_review_date\")).over(partition))\n",
    "                        .withColumn(\"user_avg_prep_time_recipes_reviewed\",\n",
    "                                    F.avg(F.col(\"minutes\")).over(partition))\n",
    "                        .withColumn(\"user_avg_n_steps_recipes_reviewed\",\n",
    "                                    F.avg(F.col(\"n_steps\")).over(partition))\n",
    "                        .withColumn(\"user_avg_n_ingredients_recipes_reviewed\",\n",
    "                                    F.avg(F.col(\"n_ingredients\")).over(partition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd4e9d3a-68ca-47b9-be53-527420e47f13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nutrition_cols = ['calories',\n",
    "                  'total_fat_per_100_cal',\n",
    "                  'sugar_per_100_cal',\n",
    "                  'sodium_per_100_cal',\n",
    "                  'protein_per_100_cal',\n",
    "                  'saturated_fat_per_100_cal',\n",
    "                  'carbohydrates_per_100_cal']\n",
    "\n",
    "for nutri_col in nutrition_cols:\n",
    "    interaction_level_df = (interaction_level_df\n",
    "                            .withColumn(\"user_avg_{}_recipes_reviewed\".format(nutri_col),\n",
    "                                        F.avg(F.col(nutri_col)).over(partition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c331a53e-f2d6-4046-b8da-718386d8d55e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code. \n",
    "\n",
    "assert(round(interaction_level_df.filter('user_id == 601529').select('user_avg_rating').first()[0], 2) == 4.22)\n",
    "assert(interaction_level_df.filter('user_id == 601529').select('user_n_ratings').first()[0] == 27)\n",
    "assert(round(interaction_level_df.filter('user_id == 601529').select('user_avg_years_betwn_review_and_submission').first()[0], 2) == 3.51)\n",
    "assert(interaction_level_df.filter('user_id == 233044').select('user_avg_prep_time_recipes_reviewed').first()[0] == 50.3)\n",
    "assert(interaction_level_df.filter('user_id == 233044').select('user_avg_n_steps_recipes_reviewed').first()[0] == 8.8)\n",
    "assert(interaction_level_df.filter('user_id == 233044').select('user_avg_n_ingredients_recipes_reviewed').first()[0] == 8.2)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_total_fat_per_100_cal_recipes_reviewed').first()[0]) == 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cc830a5-b03d-433e-99f1-fbbafb7c52a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# More Features:\n",
    "# high_ratings = 5 rating\n",
    "\n",
    "# user_avg_years_betwn_review_and_submission_high_ratings\n",
    "\n",
    "# user_avg_prep_time_recipes_reviewed_high_ratings\n",
    "\n",
    "# user_avg_n_steps_recipes_reviewed_high_ratings\n",
    "\n",
    "# user_avg_n_ingredients_recipes_reviewed_high_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5a981cf-239a-415a-aeef-c0fc2f486ba6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn(\"ind_5_rating\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(1))\n",
    "                        .withColumn(\"years_since_submission_on_review_date_5_ratings\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(F.col(\"years_since_submission_on_review_date\")))\n",
    "                        .withColumn(\"minutes_5_ratings\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(F.col(\"minutes\")))\n",
    "                        .withColumn(\"n_steps_5_ratings\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(F.col(\"n_steps\")))\n",
    "                        .withColumn(\"n_ingredients_5_ratings\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(F.col(\"n_ingredients\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e45a9b9-f84f-4280-ae67-b627c7526290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "partition = Window.partitionBy(\"user_id\")\n",
    "\n",
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn(\"user_n_5_ratings\",\n",
    "                                    F.sum(F.col(\"ind_5_rating\")).over(partition))\n",
    "                        .withColumn(\"user_avg_years_betwn_review_and_submission_5_ratings\",\n",
    "                                    F.avg(F.col(\"years_since_submission_on_review_date_5_ratings\")).over(partition))\n",
    "                        .withColumn(\"user_avg_prep_time_recipes_reviewed_5_ratings\",\n",
    "                                    F.avg(F.col(\"minutes_5_ratings\")).over(partition))\n",
    "                        .withColumn(\"user_avg_n_steps_recipes_reviewed_5_ratings\",\n",
    "                                    F.avg(F.col(\"n_steps_5_ratings\")).over(partition))\n",
    "                        .withColumn(\"user_avg_n_ingredients_recipes_reviewed_5_ratings\",\n",
    "                                    F.avg(F.col(\"n_ingredients_5_ratings\")).over(partition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8a3ff2b-8e23-4f4a-b24d-eb4742d4e291",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for nutri_col in nutrition_cols:\n",
    "    interaction_level_df = (interaction_level_df\n",
    "                            .withColumn(\"{}_5_ratings\".format(nutri_col),\n",
    "                                        F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                         .otherwise(F.col(nutri_col))))\n",
    "    interaction_level_df = (interaction_level_df\n",
    "                            .withColumn(\"user_avg_{}_recipes_reviewed_5_ratings\".format(nutri_col),\n",
    "                                        F.avg(F.col(\"{}_5_ratings\".format(nutri_col))).over(partition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa14f7e7-b89f-4833-871f-d82acf507704",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check - All rows with ratings should have non-null values in corresponding user_avg_5_ratings columns\n",
    "\n",
    "assert(interaction_level_df\n",
    "       .filter(\"rating == 5\")\n",
    "       .filter(interaction_level_df.user_n_5_ratings.isNull() |\n",
    "               interaction_level_df.user_avg_years_betwn_review_and_submission_5_ratings.isNull() |\n",
    "               interaction_level_df.user_avg_prep_time_recipes_reviewed_5_ratings.isNull() |\n",
    "               interaction_level_df.user_avg_n_steps_recipes_reviewed_5_ratings.isNull() |\n",
    "               interaction_level_df.user_avg_n_ingredients_recipes_reviewed_5_ratings.isNull())\n",
    "       .count() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8db7721-3d77-436c-878c-5f24153c2974",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check values for a given user id\n",
    "\n",
    "assert(interaction_level_df.filter('user_id == 233044').select('user_n_5_ratings').first()[0] == 7)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_years_betwn_review_and_submission_5_ratings').first()[0], 2) == 2.24)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_prep_time_recipes_reviewed_5_ratings').first()[0]) == 46)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_n_steps_recipes_reviewed_5_ratings').first()[0], 2) == 7.29)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_n_ingredients_recipes_reviewed_5_ratings').first()[0], 2) == 6.86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02ce4543-f5fd-41dc-9d77-f883d95042ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ac152f1-f43b-4c43-b393-09d1935969bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 8 Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31815514-95dc-4d88-afd8-18bb836d0774",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "115e1565-e4a2-4995-baed-34d5bec2f8dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_select = [\n",
    "    \"user_n_5_ratings\",  \n",
    "    \"user_avg_prep_time_recipes_reviewed_5_ratings\", \n",
    "    \"user_avg_n_steps_recipes_reviewed_5_ratings\", \n",
    "    \"user_avg_n_ingredients_recipes_reviewed_5_ratings\"\n",
    "]\n",
    "\n",
    "# Select and display the specified columns\n",
    "interaction_level_df.select(*columns_to_select).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "403861f7-0b6f-4478-a6c6-c52771849c21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_rating_metrics = interaction_level_df.groupBy(\"user_id\").agg(\n",
    "        round(avg(\"user_avg_rating\"),2).alias(\"Average Rating\"),\n",
    "        count(\"user_n_ratings\").alias(\"Total Reviews\"),\n",
    "        count(\"ind_5_rating\").alias(\"Total of 5-star Reviews\")\n",
    "    ).orderBy(desc(\"Total Reviews\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9b13a3b-8864-487f-9111-95c78f943358",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_rating_metrics = user_rating_metrics.filter(\n",
    "    col(\"user_id\") != 424680\n",
    ")\n",
    "\n",
    "user_rating_metrics.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6291629b-02ab-4eed-b440-76c3a5062a4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtered_df = interaction_level_df.filter(interaction_level_df[\"user_avg_prep_time_recipes_reviewed\"] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0650fdb2-bff3-4008-89c7-d054cdd62d2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, round\n",
    "\n",
    "user_recipes_metrics = filtered_df.groupBy(\"user_id\").agg(\n",
    "        round(avg(\"user_avg_prep_time_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Prepared time of 5-stars\"),\n",
    "        round(avg(\"user_avg_n_steps_recipes_reviewed_5_ratings\"), 2).alias(\"Avg No. Steps of 5-stars\"),\n",
    "        round(avg(\"user_avg_n_ingredients_recipes_reviewed_5_ratings\"), 2).alias(\"Avg No. Ingredients of 5-stars\"),\n",
    "        count(\"ind_5_rating\").alias(\"Total of 5-star Reviews\")\n",
    "    ).orderBy(desc(\"Total of 5-star Reviews\"))\n",
    "    \n",
    "user_recipes_metrics = user_recipes_metrics.filter(\n",
    "    col(\"Avg Prepared time of 5-stars\") <= 300\n",
    ")\n",
    "\n",
    "# Show the result to verify\n",
    "user_recipes_metrics.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d7e2188-0b49-4540-91d8-c219fb3436c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_recipes_metrics = user_recipes_metrics.dropna(subset=[\n",
    "    \"`Avg Prepared time of 5-stars`\", \n",
    "    \"`Avg No. Steps of 5-stars`\", \n",
    "    \"`Avg No. Ingredients of 5-stars`\"\n",
    "])\n",
    "\n",
    "# Show the result to verify\n",
    "user_recipes_metrics.show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "699c735f-1c6a-4726-886a-337df840af57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_nutrition_metrics = filtered_df.groupBy(\"user_id\").agg(\n",
    "        round(avg(\"user_avg_calories_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Calories of 5-stars\"),\n",
    "        round(avg(\"user_avg_total_fat_per_100_cal_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Total Fat per 100 of 5-stars\"),\n",
    "        round(avg(\"user_avg_sugar_per_100_cal_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Sugar per 100 of 5-stars\"),\n",
    "        round(avg(\"user_avg_sodium_per_100_cal_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Sodium per 100 of 5-stars\"),\n",
    "        round(avg(\"user_avg_protein_per_100_cal_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Prorein per 100 of 5-stars\"),\n",
    "        round(avg(\"user_avg_saturated_fat_per_100_cal_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Saturated Fat per 100 of 5-stars\"),\n",
    "        round(avg(\"user_avg_carbohydrates_per_100_cal_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Carbonhydrates per 100 of 5-stars\"),\n",
    "         count(\"ind_5_rating\").alias(\"Total of 5-star Reviews\")\n",
    "    ).orderBy(desc(\"Total of 5-star Reviews\"))\n",
    "\n",
    "user_nutrition_metrics = user_nutrition_metrics.dropna(subset=[\n",
    "    \"Avg Calories of 5-stars\", \n",
    "    \"Avg Total Fat per 100 of 5-stars\", \n",
    "    \"Avg Sugar per 100 of 5-stars\",\n",
    "    \"Avg Sodium per 100 of 5-stars\",\n",
    "    \"Avg Prorein per 100 of 5-stars\",\n",
    "    \"Avg Saturated Fat per 100 of 5-stars\",\n",
    "    \"Avg Carbonhydrates per 100 of 5-stars\",\n",
    "])\n",
    "\n",
    "user_nutrition_metrics = user_nutrition_metrics.filter(\n",
    "    col(\"user_id\") != 424680\n",
    ")\n",
    "\n",
    "# Show the result to verify\n",
    "user_nutrition_metrics.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa25d589-720a-4b68-b0ef-d9b42d80adb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 9: Create Tag-Level Features (Optional)\n",
    "- Analyze the tags column to identify valuable tags. Consider:\n",
    "> - Top 5 percentile of frequent tags.\n",
    "> - Top 5 percentile of highest-rated tags.\n",
    "> - Bottom 5 percentile of highest-rated tags.\n",
    "- Create features to capture information from these valuable tags.\n",
    "- Explore different encoding techniques (e.g., one-hot encoding, or more advanced methods) to represent tag information effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebad1b3f-cf04-4bfd-ae2f-98e79c39b501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Tags level EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43dbfc22-5bf1-4572-904b-ea0df8afcbce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_tag_level_df = interaction_level_df.withColumn('individual_tag',F.explode('tags'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ccc2031-514f-4897-8631-749b75d7242d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tags_ratings_summary = (interaction_tag_level_df\n",
    "                        .groupBy('individual_tag').agg(F.avg('rating').alias('avg_user_rating'),\n",
    "#                                                      F.max('rating').alias('max_user_rating'),\n",
    "#                                                      F.min('rating').alias('min_user_rating'),\n",
    "                                                       F.count('rating').alias('n_user_ratings'),\n",
    "                                                       F.countDistinct('id').alias('n_recipes')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3539bdd6-8cdf-4b4a-a22a-b669759aba07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interactions, recipes  =  interaction_level_df.count(), interaction_level_df.agg(F.countDistinct('id')).first()[0]\n",
    "\n",
    "tags_ratings_summary = (tags_ratings_summary.withColumn(\"in_percent_recipies\", F.col (\"n_recipes\")/F.lit(recipes))\n",
    "                                            .withColumn(\"in_percent_interactions\", F.col (\"n_user_ratings\")/F.lit(interactions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5db2f8c-f091-4fce-9184-3a746da63541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  b1. Top n most rated tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58b261b4-3b0e-4cc3-a242-f4fbd479ba81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tags_ratings_summary.sort(F.col(\"n_user_ratings\").desc()).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "665f8719-8597-46b7-8a9e-9fb34fc4d2ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tags_ratings_summary = tags_ratings_summary.filter(tags_ratings_summary.in_percent_interactions < 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bba0e4d-e177-4801-a39c-2903470be75c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_most_frequent_tags = tags_ratings_summary.sort(F.col(\"n_user_ratings\").desc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cb2413f-ef05-4211-9572-a6f1ab94ae03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles(df = top_most_frequent_tags , \n",
    "              col_name = 'in_percent_interactions', \n",
    "              quantiles_list = [0.01,0.25,0.5, 0.75,0.8,0.85,0.9,0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31a99463-039a-43ad-8e22-9545156a6863",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# keep tags appearing in the top 5 percentile \n",
    "top_most_frequent_tags = top_most_frequent_tags.filter(\"in_percent_interactions > 0.16\")\n",
    "\n",
    "top_most_frequent_tags.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1668742f-5872-499b-9996-df9755212f78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_frequent_tags_list = [data[0] for data in top_most_frequent_tags.select('individual_tag').collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2b1405e-1590-4967-9dad-48dad1baccf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df = add_OHE_columns (interaction_level_df, top_frequent_tags_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "821fce48-bd5f-42e5-8cd1-0e9ff06f1533",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Bottom n least rated tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "068d3e9e-58b0-49e2-82b6-f594350cf69f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tags_ratings_summary.sort(F.col(\"n_user_ratings\").asc()).show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c08517a5-14c8-4ec4-8ef9-41e7b895a6ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Các thẻ trên có mặt trong 1 công thức trong hơn hai trăm nghìn. Các tính năng chúng tôi tạo dựa trên các thẻ này sẽ không cung cấp thông tin mới cho mô hình. Nếu các thẻ này được mã hóa nóng, toàn bộ cột sẽ chứa số 0 và chỉ một số hàng có số 1. Một mã hóa nóng (one hot encoding) của các thẻ này không phải là một ý tưởng hay. Nếu bạn nghĩ ra một mã hóa nắm bắt được độ hiếm của các thẻ này thì chỉ khi đó bạn mới có thể thêm các thẻ này vào phân tích."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fae3b0f-a8e4-48a7-ab69-d7da3fbc49b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Top n rated tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d36361c3-8a1e-43e6-9160-c81a969a4b2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tags_ratings_summary.sort(F.col(\"avg_user_rating\").desc()).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e54ec5e0-ae3a-43ce-8c1b-9c090bf4e6c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles (tags_ratings_summary, \"n_user_ratings\", quantiles_list = [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75, 0.99])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82820d38-a65e-4ecd-a2d3-8694172f1f1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tags_ratings_summary = tags_ratings_summary.filter(tags_ratings_summary.n_user_ratings > 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01493d6c-3179-4402-9694-2eb471bfdfd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_rated_tags_df = tags_ratings_summary.sort(F.col(\"avg_user_rating\").desc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccda127f-7ae0-4750-9c89-e2ac17c2b969",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles(df = top_rated_tags_df , \n",
    "              col_name = 'avg_user_rating', \n",
    "              quantiles_list = [0.01,0.25,0.5, 0.75,0.8,0.85,0.9,0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c60ba2b-82dc-4705-aa38-974c7deb6005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# keep tags above 95 percentile\n",
    "top_rated_tags_df = top_rated_tags_df.filter(\"avg_user_rating > 4.53\")\n",
    "\n",
    "top_rated_tags_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87dd79ae-f76d-4029-ae12-76965b441c18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_rated_tags_list = [data[0] for data in top_rated_tags_df.select('individual_tag').collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "323e1f76-4feb-49b0-a844-2e5a84b1fa6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "set(top_frequent_tags_list) & set(top_rated_tags_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0f5b5e3-6d6e-4cf1-ad34-e55b92baee31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_added_columns_set = set(top_frequent_tags_list).union(set(top_rated_tags_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8506d344-d296-43b5-bc17-51d6617eb3f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df = add_OHE_columns (interaction_level_df, top_rated_tags_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d5b9df2-5de4-46ed-ae2b-4df97a454c40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_rated_tags_df.orderBy(\"avg_user_rating\", ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f459cdd-deb9-47d7-bc07-22134c22f9a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Bottom n rated tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "197980c0-ce03-4d27-892d-e4e1042e9603",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_rated_tags_df = tags_ratings_summary.sort(F.col(\"avg_user_rating\").asc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "155e2625-7ddc-4b6a-8a2f-0b4984e8e901",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles (bottom_rated_tags_df, \"avg_user_rating\", quantiles_list = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75, 0.99])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fc51901-f26a-47dc-ae22-bf238f2fda29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_rated_tags_df = bottom_rated_tags_df.filter(\"avg_user_rating < 4.00\")\n",
    "\n",
    "bottom_rated_tags_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6472bd82-6333-42cd-9ea0-0a9a7487701b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_rated_tags_list = [data[0] for data in bottom_rated_tags_df.select('individual_tag').collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f351293-797f-4846-8531-fe8e1e7b3e22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_added_columns_set & set(bottom_rated_tags_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a439614-2036-452c-9149-41d352c9cbf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df =  add_OHE_columns(interaction_level_df, bottom_rated_tags_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "578755b9-f96e-4c87-a4ad-8b7191ac8651",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_rated_tags_df.orderBy(\"avg_user_rating\", desc = True).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c502cdc-b712-4ae9-9182-bce8e8e00ab4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_rated_tags_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f0f12c1-b5a7-48d2-a372-5420447c01f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Final DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59b2f0dd-adf4-40d1-ad71-42ae22994d6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(interaction_level_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06d2435a-6def-42da-9cdc-15e1b49a23cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.write.mode(\"overwrite\").parquet(\"interaction_level_df_BDA\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Group 01 Assignment_Recipes Recommendation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
