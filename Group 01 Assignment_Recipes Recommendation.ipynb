{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa07a252-122a-4926-87f6-2e428cc1151d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "# Import module\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, split, regexp_extract\n",
    "# Import for typecasting columns\n",
    "from pyspark.sql.types import IntegerType,BooleanType,DateType,FloatType,StringType\n",
    "from pyspark.sql.types import ArrayType\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ca41ba-f7a0-47d5-bd01-a7a0652609db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"RecipeRecommender\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04ac9880-0ec7-434d-ac8f-5b2a8939c227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Task 1**: Read the Data\n",
    "- Read RAW_recipes_cleaned.csv from the provided link.\n",
    "- Ensure all fields have the correct data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09a0a93e-03a4-43c8-bfa8-99eccd5119d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Task 1: Read the Data\n",
    "Raw_Recipe_Data = (spark.read.csv(\"dbfs:/FileStore/RAW_recipes_cleaned.csv\", header=True,inferSchema=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08bf90d2-ac75-43a9-bf65-78f32477fd2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Show schema\n",
    "Raw_Recipe_Data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad85cf6a-cd1b-4580-a13a-436d48624655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Show the first 5 rows of data\n",
    "# Raw_Recipe_Data.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "630bfa13-6640-48b1-96c1-124ed3db39cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Task 2**: Extract Nutrition Features\n",
    "The nutrition column is currently read as a string. Extract the seven individual nutrition values from each row and create separate columns:\n",
    "- calories\n",
    "- total_fat_PDV\n",
    "- sugar_PDV\n",
    "- sodium_PDV\n",
    "- protein_PDV\n",
    "- saturated_fat_PDV\n",
    "- carbohydrates_PDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01f9858e-9f72-47ae-8130-6598b5b4304a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# String operations to remove square brakets\n",
    "Raw_Recipe_Data.select('nutrition').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567215c0-40cb-4662-b417-f5c032b82c69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List of nutrition columns\n",
    "\n",
    "Nutrition_Col_Names = ['calories',\n",
    "                          'total_fat_PDV',\n",
    "                          'sugar_PDV',\n",
    "                          'sodium_PDV',\n",
    "                          'protein_PDV',\n",
    "                          'saturated_fat_PDV',\n",
    "                          'carbohydrates_PDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e44bf18-b92e-4f6d-9d9b-e4505e8446b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# STEP 2.1 string operations to remove square brakets in 'nutrition' column\n",
    "Raw_Recipe_Data = (Raw_Recipe_Data\n",
    "                  .withColumn('nutrition',(F.regexp_replace(\"nutrition\",\"[\\[\\]]\",\"\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fff4d0e3-60ef-4b4f-b9b2-c1156aaabb49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task 02 Cell 2 out of 3\n",
    "# STEP 2.2 - split the neutrition string into seven individial values. \n",
    "# Create an object to split the nutrition column\n",
    "\n",
    "import pyspark\n",
    "\n",
    "Nutrition_Col_Split = pyspark.sql.functions.split(Raw_Recipe_Data['nutrition'],',')\n",
    "for col_index, col_name in enumerate(Nutrition_Col_Names):\n",
    "    Raw_Recipe_Data = (Raw_Recipe_Data.withColumn(col_name, Nutrition_Col_Split.getItem(col_index).cast(\"float\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63c55ce5-af49-4b45-baf8-0dc14c49e450",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Test cases for task 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b816cf9a-34f3-407b-8a00-854e3a77120e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert Raw_Recipe_Data.schema[\"carbohydrates_PDV\"].dataType == FloatType(), \"Recheck your typecasting\"\n",
    "assert Raw_Recipe_Data.collect()[123432][14] == 62.0, \"The columns have not been split correctly.\"\n",
    "assert Raw_Recipe_Data.collect()[10000][12] == 60.400001525878906, \"The columns have not been split correctly.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "532e05ba-8ed1-44d8-97fb-70dc1a1f4650",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 3: Standardize Nutrition Values\n",
    "Standardize the nutrition values to a per 100 calorie basis to account for serving size variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb6ed987-a4b7-472d-a868-ca5420e1578d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task 03 Cell 1 out of 1\n",
    "\n",
    "for nutrition_col in Nutrition_Col_Names:# loop over each of the newly created nutrition columns \n",
    "    if nutrition_col != \"calories\":\n",
    "        # the calories column should not be a part of the transformation exercise\n",
    "        # following code will name the new columns \n",
    "        nutrition_per_100_cal_col = (nutrition_col\n",
    "                                 .replace('_PDV','')\n",
    "                                 +'_per_100_cal')\n",
    "        Raw_Recipe_Data = Raw_Recipe_Data.withColumn(nutrition_per_100_cal_col,\n",
    "                                               Raw_Recipe_Data[nutrition_col]*100/Raw_Recipe_Data[\"calories\"]\n",
    "                                                # pyspark code to recreate the intended transformation \n",
    "                                                  )\n",
    "        \n",
    "        # You might end up adding nulls to the data because of our intended transformation. \n",
    "        # Perform a fill na operation to fill all the nulls with 0s. \n",
    "        # You must limit the scope of the fill na to the current column only. \n",
    "        \n",
    "        Raw_Recipe_Data = Raw_Recipe_Data.fillna(value=0,subset=[nutrition_per_100_cal_col]) \n",
    "        # pyspark code to fill nulls with 0 in only the current nutrition_per_100_cal_col            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b164bd2b-ae47-4b93-ac6e-f1a85620ce42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Raw_Recipe_Data.toPandas().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff8724a5-bef9-4e07-90f9-e5b2ca18330d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 4: Convert Tags to Array\n",
    "The tags column is currently read as a string. Convert it to an array of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62eb9ad1-694a-4bee-b98f-537f568520a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task 04 Cell 1 out of 1\n",
    "Raw_Recipe_Data = (Raw_Recipe_Data\n",
    "                  .withColumn('tags', F.regexp_replace(\"tags\",\"[\\\\[\\\\]\\\\']\",\"\")\n",
    "                             )\n",
    "                  .withColumn('tags', F.split(\"tags\",\", \")\n",
    "                             )\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0be481e3-3c36-4e5a-bc07-f28004255fd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Raw_Recipe_Data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da285ef4-05da-416e-abc5-4868fdcef37c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Raw_Recipe_Data.schema[\"tags\"].dataType == ArrayType(StringType(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d36b9cd7-6f0c-4a42-b585-17fa59b13c87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Raw_Recipe_Data.toPandas().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd4241b9-490c-4154-9776-4eb462e382df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 5: Read and Join Interaction Data\n",
    "- Read RAW_interactions_cleaned.csv from the provided link.\n",
    "- Join this interaction data with the recipe data using the appropriate key. The resulting dataframe should contain all interactions with corresponding recipe information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "407c160d-fb71-48ac-bcf5-92a3cbf57a44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Raw_Ratings_Data = (spark.read.csv('dbfs:/FileStore/RAW_interactions_cleaned.csv', \n",
    "                                 header=True, \n",
    "                                 inferSchema= True)\n",
    "                  .withColumn(\"review_date\",  F.col(\"date\"))\n",
    "                  .drop(F.col(\"date\"))\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d020d0-bbd2-473c-ae54-333096c65402",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Raw_Ratings_Data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "561a788a-6f71-4020-aae5-70b007a08e6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert Raw_Ratings_Data.count() == 1132367, \"There is a mistake in reading the data.\"\n",
    "assert len(Raw_Ratings_Data.columns) == 5, \"There is a mistake in reading the data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b35c5115-8f9b-44e9-9249-add7efafd16d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Raw_Ratings_Data.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bdadb5b-b87d-4459-9b9d-ffd4390b825f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task 05 Cell 1 out of 1\n",
    "interaction_level_df = Raw_Ratings_Data.join(Raw_Recipe_Data,Raw_Ratings_Data.recipe_id == Raw_Recipe_Data.id,\"inner\")\n",
    "                                           # add the key on which the join should happen\n",
    "                                           # mention the type of join expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b301824d-55a7-45d2-9f8a-ec3b2a149591",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Test cases for Task 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36713182-7437-44db-88a8-64672dbf4ca5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert (interaction_level_df.count() ,len(interaction_level_df.columns)) == (1132367, 30), \"The type of join is incorrect\"\n",
    "\n",
    "lst1 = Raw_Ratings_Data.select('recipe_id').collect()\n",
    "lst2 = Raw_Recipe_Data.select('id').collect()\n",
    "exclusive_set = set(lst1)-set(lst2)\n",
    "\n",
    "assert len(exclusive_set) == 0, \"There is a mistake in reading one of the two data files.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2acd57d4-7e10-4816-b4d0-1a66b741f2df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 6: Create Time-Based Features\n",
    "Create features that capture the time elapsed between a review date and the recipe's submission date. Use the date (from interactions data) and submitted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c99b33e-8951-496a-99ee-a143bb5a5515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn('days_since_submission_on_review_date',F.datediff(\"review_date\",\"submitted\")\n",
    "                                     # Pyspark function to find the number of days between two dates              \n",
    "                                   )\n",
    "                        .withColumn('months_since_submission_on_review_date',F.months_between(\"review_date\",\"submitted\")\n",
    "                                     # Pyspark function to find the number of months between two dates          \n",
    "                                   )\n",
    "                        .withColumn('years_since_submission_on_review_date',F.months_between(\"review_date\",\"submitted\")/12\n",
    "                                     # Pyspark function to find the number of months between two dates / 12          \n",
    "                                   )\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ebf67fe-3f0a-4685-9a13-3049b32ecaec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Test cases for Task 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cab96bb7-085b-4e10-963c-c1e91f4f8ed6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "assert interaction_level_df.schema[\"days_since_submission_on_review_date\"].dataType == IntegerType()\n",
    "\n",
    "assert (interaction_level_df.filter((interaction_level_df.user_id == 428885) & (interaction_level_df.recipe_id == 335241))\n",
    "                            .select('days_since_submission_on_review_date').collect()[0][0]) == 77\n",
    "assert (interaction_level_df.filter((interaction_level_df.user_id == 2025676) & (interaction_level_df.recipe_id == 94265))\n",
    "                            .select('months_since_submission_on_review_date').collect()[0][0]) == 153.22580645\n",
    "assert (interaction_level_df.filter((interaction_level_df.user_id == 338588) & (interaction_level_df.recipe_id == 21859))\n",
    "                            .select('years_since_submission_on_review_date').collect()[0][0]) == 4.564516129166667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dbf1bc2-bcc4-49ec-bf18-ac2f3fc3cf8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bad810f-1d5e-4d58-a719-8fee7a7c8cbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# interaction_level_df.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b16e5bb9-fbbb-45e5-81cc-da8c1b9a7a88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the data we have created so far in a parquet file\n",
    "interaction_level_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bcdfc66-6d86-4595-b590-3617d79bbc5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert (interaction_level_df.count() ,len(interaction_level_df.columns) ) == (1132367, 33)\n",
    "(interaction_level_df.count() ,len(interaction_level_df.columns) ) == (1132367, 33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af7dbb8d-34e2-4e46-9f49-1981f9f2303c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Write the raw_recipes_df\n",
    "## create a folder named data in you current directry before running this. \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "interaction_level_df.write.parquet(\"dbfs:/FileStore/interaction_level_df\") # Modify the path as you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "130c6e06-b530-4e6d-8de7-21e35062c7bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdf87b0f-fbb1-4fd0-93ee-e4dbc2a460e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initial Setup\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cad701fa-659d-4c79-a4fb-56bdad5eccbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this everytime you create a new spark instance. \n",
    "\n",
    "# Use %pip to install the required libraries\n",
    "%pip install plotly==5.5.0\n",
    "%pip install pandas==0.25.1\n",
    "%pip install numpy==1.14.5\n",
    "%pip install matplotlib==3.1.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2398b92d-ad7d-46d6-9e01-c94a0f0e4bb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import for typecasting columns\n",
    "from pyspark.sql.types import IntegerType,BooleanType,DateType,FloatType,StringType\n",
    "from pyspark.sql.types import ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11f7f0ca-e66c-4083-bbc5-e3fb262c7e35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defining Custom Functions\n",
    "def get_quantiles(df, col_name, quantiles_list = [0.01, 0.25, 0.5, 0.75, 0.99]):\n",
    "    \"\"\"\n",
    "    Takes a numerical column and returns column values at requested quantiles\n",
    "\n",
    "    Inputs \n",
    "    Argument 1: Dataframe\n",
    "    Argument 2: Name of the column\n",
    "    Argument 3: A list of quantiles you want to find. Default value [0.01, 0.25, 0.5, 0.75, 0.99]\n",
    "\n",
    "    Output \n",
    "    Returns a dictionary with quantiles as keys and column quantile values as values \n",
    "    \"\"\"\n",
    "    # Get min, max and quantile values for given column\n",
    "    min_val = df.agg(F.min(col_name)).first()[0]\n",
    "    max_val = df.agg(F.max(col_name)).first()[0]\n",
    "    quantiles_vals = df.approxQuantile(col_name,\n",
    "                                       quantiles_list,\n",
    "                                       0)\n",
    "  \n",
    "    # Store min, quantiles and max in output dict, sequentially\n",
    "    quantiles_dict = {0.0:min_val}\n",
    "    quantiles_dict.update(dict(zip(quantiles_list, quantiles_vals)))\n",
    "    quantiles_dict.update({1.0:max_val})\n",
    "    return(quantiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dab5af8-9692-4206-9062-c95a7059839d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_bucketwise_statistics(summary, bucketizer):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and a bucketizer object and plots the summary statistics for each bucket in the dataframe. \n",
    "  \n",
    "    Inputs\n",
    "    Argument 1: Pandas dataframe obtained from bucket_col_print_summary function \n",
    "    Argument 2: Bucketizer object obtained from bucket_col_print_summary function\n",
    "  \n",
    "    Output\n",
    "    Displays a plot of bucketwise average ratings and number of ratings for a parameter.   \n",
    "    \"\"\"\n",
    "    # Creating bucket labels from splits\n",
    "    classlist = bucketizer.getSplits()\n",
    "    number_of_classes = len(classlist) - 1\n",
    "\n",
    "    class_labels = []\n",
    "    hover_labels = []\n",
    "    for i in range(number_of_classes):\n",
    "        hover_labels.append(str(classlist[i]) + \"-\" + str(classlist[i+1]) + \" (Bucket name: \" + str(int(i)) + \")\")\n",
    "        class_labels.append(str(classlist[i]) + \"-\" + str(classlist[i+1]))\n",
    "  \n",
    "    summary[\"Scaled_number\"] = (summary[\"n_ratings\"] - summary[\"n_ratings\"].min()) / (summary[\"n_ratings\"].max() - summary[\"n_ratings\"].min()) + 1.5\n",
    "    summary['Bucket_Names'] = class_labels\n",
    "  \n",
    "    # Making the plot\n",
    "    x = summary[\"Bucket_Names\"]\n",
    "    y1 = summary[\"avg_rating\"]\n",
    "    y2 = summary[\"n_ratings\"]\n",
    "    err = summary[\"stddev_rating\"]  \n",
    "\n",
    "    # Setting up the figure\n",
    "    plt.rcParams[\"figure.figsize\"] = [summary.shape[0] + 2, 6.0]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Bars with dark blue color\n",
    "    bar = ax1.bar(x, y1, color=\"#00008B\")\n",
    "    ax1.errorbar(x, y1, yerr=err, fmt=\"o\", color=\"#FFD700\")  # Error bars in dark yellow\n",
    "    ax1.set(ylim=(0, 7))\n",
    "  \n",
    "    # Add labels above the bars\n",
    "    def barlabel(x_list, y_list):\n",
    "        for i in range(len(x_list)):\n",
    "            ax1.text(i, y_list[i] + 0.2, y_list[i], ha='center',\n",
    "                     fontdict=dict(size=10),\n",
    "                     bbox=dict(facecolor='#00008B', alpha=0.2))\n",
    "    barlabel(summary[\"Bucket_Names\"].tolist(), summary[\"avg_rating\"].round(2).tolist())\n",
    "  \n",
    "    # Scatter plot with dark yellow color\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.scatter(x, y2, s=summary[\"Scaled_number\"] * 500, c=\"#FFD700\")  \n",
    "    ax2.set(ylim=(0, summary[\"n_ratings\"].max() * 1.15))\n",
    "\n",
    "    # Add labels above the scatter points\n",
    "    def scatterlabel(x_list, y_list):\n",
    "        for i in range(len(x_list)):\n",
    "            ax2.text(i, y_list[i] + 15000, y_list[i], ha='center',\n",
    "                     fontdict=dict(size=10),\n",
    "                     bbox=dict(facecolor='#FFD700', alpha=0.5))\n",
    "    scatterlabel(summary[\"Bucket_Names\"].tolist(), summary[\"n_ratings\"].tolist())\n",
    "  \n",
    "    # Giving labels to the axes\n",
    "    ax1.set_xlabel(bucketizer.getOutputCol(), fontdict=dict(size=14)) \n",
    "    ax1.set_ylabel(\"Average Ratings\", fontdict=dict(size=14))\n",
    "  \n",
    "    # Secondary y-axis label\n",
    "    ax2.set_ylabel('Number of Ratings', fontdict=dict(size=14))\n",
    "  \n",
    "    # Plot title\n",
    "    plt.title('Average ratings for each bucket and the quantity of ratings for \\n' + bucketizer.getInputCol(), \n",
    "              fontdict=dict(size=14))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c7b12f8-3540-4139-9028-864419b78aa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def bucket_col_print_summary(df, splits, inputCol, outputCol):\n",
    "    \"\"\"\n",
    "    Given a numerical column in a data frame, adds a bucketized version of the column to the data frame, according to splits provided.\n",
    "    Also prints a summary of ratings seen in each bucket made.\n",
    "\n",
    "    Inputs \n",
    "    Argument 1: Data Frame \n",
    "    Argument 2: Values at which the column will be split\n",
    "    Argument 3: Name of the input column (numerical column)\n",
    "    Argument 4: Name of the output column (bucketized numerical column)\n",
    "\n",
    "    Output: \n",
    "    1) New dataframe with the output column added\n",
    "    2) Bucketizer object trained from the input column \n",
    "    3) Pandas dataframe with summary statistics for ratings seen in buckets of the output column\n",
    "    Also plots summary statistics for ratings seen in buckets of the output column\n",
    "    \"\"\"\n",
    "\n",
    "    # Dropping bucket if it already exists\n",
    "    if outputCol in df.columns:\n",
    "        df = df.drop(outputCol)\n",
    "\n",
    "    # Training bucketizer\n",
    "    bucketizer = Bucketizer(splits = splits,\n",
    "                            inputCol  = inputCol,\n",
    "                            outputCol = outputCol)\n",
    "    \n",
    "    df = bucketizer.setHandleInvalid(\"keep\").transform(df)\n",
    "\n",
    "    # Printing meta information on buckets created\n",
    "    print(\"Added bucketized column {}\".format(outputCol))\n",
    "    print(\"\")\n",
    "    print(\"Bucketing done for split definition: {}\".format(splits))\n",
    "    print(\"\")  \n",
    "    print(\"Printing summary statistics for ratings in buckets below:\")\n",
    "\n",
    "    # Creating a summary statistics dataframe and passing it to the plotting function\n",
    "    summary =  (df\n",
    "                .groupBy(outputCol)\n",
    "                .agg(F.avg('rating').alias('avg_rating'),\n",
    "                     F.stddev('rating').alias('stddev_rating'),\n",
    "                     F.count('rating').alias('n_ratings'))\n",
    "                .sort(outputCol)\n",
    "                .toPandas())\n",
    "  \n",
    "    plot_bucketwise_statistics(summary,bucketizer)\n",
    "  \n",
    "    return df, bucketizer, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f24f9e3-8246-4227-9245-8210debae501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_column_distribution_summary(df, col_name):\n",
    "    \"\"\"\n",
    "    Takes a column in a data frame and prints the summary statistics (average, standard deviation, count and distinct count) for all unique values in that column.\n",
    "  \n",
    "    Inputs \n",
    "    Argument 1: Dataframe \n",
    "    Argument 2: Name of the column\n",
    "  \n",
    "    Output\n",
    "    Returns nothing \n",
    "    Prints a Dataframe with summary statistics\n",
    "    \"\"\"\n",
    "    print(df\n",
    "          .groupBy(col_name)\n",
    "          .agg(F.avg('rating').alias('avg_rating'),\n",
    "               F.stddev('rating').alias('stddev_rating'),\n",
    "               F.count('rating').alias('n_ratings'),\n",
    "               F.countDistinct('id').alias('n_recipes'))\n",
    "          .sort(F.col(col_name).asc())\n",
    "          .show(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd606399-a39c-4132-acbb-8cdffaead50c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_n_items_satisfying_condition (df, condition, aggregation_level = \"recipe\"):\n",
    "    \"\"\"\n",
    "    Given a condition, find the number of recipes / reviews that match the condition.\n",
    "    Also calculates the percentage of such recipes / reviews as a percentage of all recipes / reviews.\n",
    "  \n",
    "    Inputs \n",
    "    Argument 1: Dataframe \n",
    "    Argument 2: Logical expression describing a condition, string type. eg: \"minutes == 0\"\n",
    "    Argument 3: Aggregation level for determining \"items\", either  \"recipe\" or \"review\". Default value == \"recipe\"\n",
    "  \n",
    "    Output: Returns no object.\n",
    "    Prints the following:\n",
    "    1) Number of recipes / reviews that satisfy the condition\n",
    "    2) Total number of recipes / reviews in the dataframe\n",
    "    3) Percentage of recipes / reviews that satisfy the condition\n",
    "    \"\"\"\n",
    "    # Find out num rows satisfying the condition\n",
    "    if aggregation_level == \"recipe\": \n",
    "        number_of_rows_satisfying_condition = (df\n",
    "                                             .filter(condition)\n",
    "                                             .agg(F.countDistinct(\"id\"))).first()[0]\n",
    "      \n",
    "        n_rows_total = (df.agg(F.countDistinct(\"id\"))).first()[0]\n",
    "    if aggregation_level == \"review\":\n",
    "        number_of_rows_satisfying_condition = (df\n",
    "                                             .filter(condition)\n",
    "                                             .agg(F.countDistinct(\"id\",\"user_id\"))).first()[0]\n",
    "        n_rows_total = (df.agg(F.countDistinct(\"id\",\"user_id\"))).first()[0]\n",
    "  \n",
    "    # Find out % rows satisfying the conditon and print a properly formatted output\n",
    "    perc_rows = round(number_of_rows_satisfying_condition * 100/ n_rows_total, 2)\n",
    "    print('Condition String                   : \"{}\"'.format(condition))\n",
    "    print(\"Num {}s Satisfying Condition   : {} [{}%]\".format(aggregation_level.title(), number_of_rows_satisfying_condition, perc_rows))\n",
    "    print(\"Total Num {}s                  : {}\".format(aggregation_level.title(), n_rows_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77cb869e-6d76-4ccd-88ae-99c95b8a0559",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "# Read interaction_level_df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56c1b0c1-6372-42b6-b9a5-08560759d987",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df_processed = spark.read.parquet(\"dbfs:/FileStore/interaction_level_df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2388a6e9-e883-441c-bd46-9d126a4c7638",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert interaction_level_df.count() == 1132367, \"There is a mistake in reading the data.\"\n",
    "assert len(interaction_level_df.columns) == 33, \"There is a mistake in reading the data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "463f34d5-0f87-4d51-84ad-49d6597f26e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "862b26bd-a380-4bd9-bbc8-9077cb50c5d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.toPandas().head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fc1031f-c3a1-479f-b2d4-1df8afbcc5a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 7: Process Numerical Columns (Optional)\n",
    "- Introduce non-linearity to numerical columns by converting them into categorical columns using binning (percentile-based bucketing).\n",
    "- Columns to consider:\n",
    "> - years_since_submission_on_review_date\n",
    "> - minutes\n",
    "> - calories\n",
    "> - total_fat_PDV\n",
    "> - sugar_PDV\n",
    "> - sodium_PDV\n",
    "> - protein_PDV\n",
    "> - saturated_fat_PDV\n",
    "> - carbohydrates_PDV\n",
    "- Analyze the average rating for each bucket to determine the usefulness of the bucketed column.\n",
    "- Handle any data inconsistencies or edge cases (e.g., reviews before submission date) appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8409449b-5c20-4d89-be55-1e7f2be1b333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Bucketing and Cleaning Numerical Features\n",
    "\n",
    "# 1. years_since_submission_on_review_date\n",
    "\n",
    "# [Review Time Since Submission]\n",
    "\n",
    "# Recipes more than 6 years old are rated low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7c25ede-c3ee-4212-9515-1399807dc9ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles(df = interaction_level_df,\n",
    "             col_name = \"years_since_submission_on_review_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "843ee242-a69a-4578-967d-b1a7fefadf14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "get_n_items_satisfying_condition(df = interaction_level_df,\n",
    "                                 condition= 'years_since_submission_on_review_date < 0',\n",
    "                                 aggregation_level= \"review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39f78cf2-d852-48d7-a1b3-3c4bede45196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Only keep interactions with review dates >= recipe submission date\n",
    "\n",
    "interaction_level_df = (interaction_level_df\n",
    "                        .filter('years_since_submission_on_review_date >= 0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10ec68fb-491c-4656-bdcb-f04844e4702d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "splits = [ 0, 1, 3, 6, float('Inf')]\n",
    "inputCol  = \"years_since_submission_on_review_date\"\n",
    "outputCol = \"years_since_submission_on_review_date_bucket\"\n",
    "\n",
    "(interaction_level_df, submission_time_bucketizer, submission_time_pandas_df) = bucket_col_print_summary(df = interaction_level_df,\n",
    "                                                                              splits = splits,\n",
    "                                                                              inputCol  = inputCol,\n",
    "                                                                              outputCol = outputCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93a12058-f717-41e0-b5d5-3a194cd1a372",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%matplot plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa68a16f-1f38-4551-a00e-963deafcb053",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. minutes\n",
    "# [prep time]\n",
    "\n",
    "# Somewhat relevant\n",
    "# Low prep time is preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44ed743a-2ce0-46bb-875c-730ca13db24d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles(df = interaction_level_df,\n",
    "              col_name = \"minutes\",\n",
    "              quantiles_list=[0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d0fb1a5-d74c-4d15-bc0e-5b28f4774793",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Capping prep time at 930 minutes\n",
    "\n",
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn(\"minutes\",\n",
    "                                    F.when(interaction_level_df[\"minutes\"] > 930, 930)\n",
    "                                     .otherwise(interaction_level_df[\"minutes\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d4827a7-b93b-42b0-9ed9-590f4d36665d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# let's look at some examples with 1 step only to see if this makes sense\n",
    "\n",
    "interaction_level_df.filter('minutes == 0 and n_steps == 1').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a84957f0-5c68-4751-81e2-5c8d14231284",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_n_items_satisfying_condition(df = interaction_level_df,\n",
    "                                 condition = 'minutes == 0',\n",
    "                                 aggregation_level = \"recipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3740548-cec2-4371-936d-7f2d16ced886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove recipes with cook time zero\n",
    "\n",
    "interaction_level_df = interaction_level_df.filter(\"minutes > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cad63a64-340c-4fb0-b592-a40082ad6196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_n_items_satisfying_condition(df = interaction_level_df,\n",
    "                                 condition = 'minutes == 0',\n",
    "                                 aggregation_level = \"recipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2c86c43-ee5f-4d2a-aa5e-0e7c294378c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "splits = [0, 15, 30, 60, float('Inf')]\n",
    "inputCol  = \"minutes\"\n",
    "outputCol = \"prep_time_bucket\"\n",
    "\n",
    "(interaction_level_df, prep_time_bucketizer, prep_time_summary_pandas_df) = bucket_col_print_summary(df = interaction_level_df,\n",
    "                                                                              splits = splits,\n",
    "                                                                              inputCol  = inputCol,\n",
    "                                                                              outputCol = outputCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58bdc561-2a11-4a22-ba66-e26a63bc84ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%matplot plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02c22f03-ac9b-4563-bfb4-42e047d38584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. n_steps\n",
    "# Clearly relevant\n",
    "\n",
    "# Recipes with less than 2 steps are rated high\n",
    "\n",
    "# Recipes with more than 29 steps are rated very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17edc71a-ac16-42d7-9ee9-e57bb885d2e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles(df = interaction_level_df,\n",
    "              col_name = \"n_steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dcdc68c-8f91-44e1-a852-a8620e30c328",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.filter('n_steps == 0').show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a82c1092-83f4-4d91-93a8-46e752b3edeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_n_items_satisfying_condition(df = interaction_level_df,\n",
    "                                 condition = 'n_steps == 0',\n",
    "                                 aggregation_level = \"recipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c9b5201-a581-4829-8185-5a9dc35f73d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove recipes with n_steps zero\n",
    "\n",
    "interaction_level_df = interaction_level_df.filter(\"n_steps > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ad016b8-7f1d-4fd0-b529-7c7531ca19f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "splits = [0, 2, 6, 8, 12, 29, float('Inf')]\n",
    "inputCol  = \"n_steps\"\n",
    "outputCol = \"n_steps_bucket\"\n",
    "\n",
    "(interaction_level_df, n_steps_bucketizer, n_steps_pandas_df) = bucket_col_print_summary(df = interaction_level_df,\n",
    "                                                                              splits = splits,\n",
    "                                                                              inputCol  = inputCol,\n",
    "                                                                              outputCol = outputCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a837bbf1-3063-44c4-b6b4-36ffcbb86f14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%matplot plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a2786ba-4c14-4a29-9bd5-f49e89582ec1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. n_ingredients\n",
    "\n",
    "# Not relevant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e099a5f9-bbe6-424f-a098-ea38818bc42b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles(df = interaction_level_df,\n",
    "              col_name = \"n_ingredients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "911e710d-09fa-4707-9ab4-6e43101b836d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "splits = [0, 6, 9, 11, float('Inf')]\n",
    "inputCol  = \"n_ingredients\"\n",
    "outputCol = \"n_ingredients_bucket\"\n",
    "\n",
    "(interaction_level_df, n_ingredients_bucketizer, n_ingredients_pandas_df) = bucket_col_print_summary(df = interaction_level_df,\n",
    "                                                                              splits = splits,\n",
    "                                                                              inputCol  = inputCol,\n",
    "                                                                              outputCol = outputCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ff93642-78cb-4ac6-b928-af84aba7c69b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%matplot plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79497146-9505-4b75-bec7-99748552dd2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. nutrition columns\n",
    "# calories - Calories per serving seems irrelevant\n",
    "# fat (per 100 cal) - Calories per serving seems irrelevant\n",
    "# sugar (per 100 cal) - Calories per serving seems irrelevant\n",
    "# sodium (per 100 cal) - Calories per serving seems irrelevant\n",
    "# protein (per 100 cal) - Calories per serving seems irrelevant\n",
    "# sat. fat (per 100 cal) - Calories per serving seems irrelevant\n",
    "# carbs (per 100 cal) - Calories per serving seems irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b25629a6-144c-42ff-b433-d37ac82473e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8f54c94-ad5a-4d87-b56f-89c8e45cea12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nutrition_cols = ['calories', \n",
    "                  'total_fat_PDV', \n",
    "                  'sugar_PDV', \n",
    "                  'sodium_PDV', \n",
    "                  'protein_PDV', \n",
    "                  'saturated_fat_PDV', \n",
    "                  'carbohydrates_PDV', \n",
    "                  'total_fat_per_100_cal', \n",
    "                  'sugar_per_100_cal', \n",
    "                  'sodium_per_100_cal', \n",
    "                  'protein_per_100_cal', \n",
    "                  'saturated_fat_per_100_cal', \n",
    "                  'carbohydrates_per_100_cal']\n",
    "\n",
    "quantiles_list = [0.00, 0.05, 0.25, 0.5, 0.75, 0.95, 1.00]\n",
    "nutrition_col_quantiles = pd.DataFrame(index = quantiles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d32d24a1-ccfa-4ea6-bc41-dee24b4a4006",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for col in nutrition_cols:\n",
    "    nutrition_col_quantiles[col] = (get_quantiles(df = interaction_level_df,\n",
    "                                                col_name = col,\n",
    "                                                quantiles_list=quantiles_list)\n",
    "                                  .values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bbdfb1c-28ce-446e-a552-718c171580f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nutrition_col_quantile_summary = pd.DataFrame(index = [\"0.00-0.25\", \"0.25-0.50\", \"0.50-0.75\", \"0.75-0.95\", \"0.95 - 1.00\"])\n",
    "\n",
    "for col in nutrition_cols:\n",
    "    splits = ([0]\n",
    "            + list(nutrition_col_quantiles.loc[[0.25, 0.5, 0.75, 0.95], col].round())\n",
    "            + [float('Inf')])\n",
    "    inputCol  = col\n",
    "    outputCol = col+\"_bucket\"\n",
    "\n",
    "    if outputCol in interaction_level_df.columns:\n",
    "        interaction_level_df = interaction_level_df.drop(outputCol)\n",
    "\n",
    "  # Training bucketizer\n",
    "    bucketizer = Bucketizer(splits = splits,\n",
    "                          inputCol  = inputCol,\n",
    "                          outputCol = outputCol)\n",
    "  \n",
    "    interaction_level_df = bucketizer.setHandleInvalid(\"keep\").transform(interaction_level_df)\n",
    "  \n",
    "    nutrition_col_quantile_summary.loc[:, col] = (interaction_level_df\n",
    "                                                .groupBy(outputCol)\n",
    "                                                .agg(F.avg('rating').alias('avg_rating'))\n",
    "                                                .sort(outputCol)\n",
    "                                                .select('avg_rating').toPandas().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8c37d20-77a2-4f64-a6dc-cb73f1fa7a54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set the max columns to none\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7f69d39-a741-4488-9ca3-e93d0a898dab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nutrition_col_quantile_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bbf1304-830d-46aa-934b-d1c59d56b135",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 8: Create User-Level Features (Optional)\n",
    "- Create features that capture user preferences and rating tendencies:\n",
    "> - user_avg_rating\n",
    "> - user_avg_n_ratings\n",
    "> - user_avg_years_betwn_review_and_submission\n",
    "> - user_avg_prep_time_recipes_reviewed\n",
    "> - user_avg_n_steps_recipes_reviewed\n",
    "> - user_avg_n_ingredients_recipes_reviewed\n",
    "> - user_avg_years_betwn_review_and_submission_high_ratings\n",
    "> - user_avg_calories_recipes_reviewed\n",
    "> - user_avg_total_fat_per_100_cal_recipes_reviewed\n",
    "> - user_avg_sugar_per_100_cal_recipes_reviewed\n",
    "> - user_avg_sodium_per_100_cal_recipes_reviewed\n",
    "> - user_avg_protein_per_100_cal_recipes_reviewed\n",
    "> - user_avg_saturated_fat_per_100_cal_recipes_reviewed\n",
    "> - user_avg_carbohydrates_per_100_cal_recipes_reviewed\n",
    "> - user_avg_prep_time_recipes_reviewed_high_ratings\n",
    "> - user_avg_n_steps_recipes_reviewed_high_ratings\n",
    "> - user_avg_n_ingredients_recipes_reviewed_high_ratings\n",
    "- \"High ratings\" refers to reviews with a rating of 5.\n",
    "- Check for and handle any null values introduced during feature creation.\n",
    "- Consider bucketing these user-level features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b88c0cf-50ff-4cdb-a483-7ea3b86d18c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 03_FEATURE_EXTRACTION_PART\n",
    "\n",
    "# Initial Setup (2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b5cf2f8-4cf4-4fbc-9f24-fe584037725e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d96b84db-1182-412d-9fb0-a7d81ee10e37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe2da961-1fd6-444d-ae5e-0a9334d26277",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run this everytime you create a new spark instance. \n",
    "\n",
    "spark.sparkContext.install_pypi_package(\"plotly==5.5.0\")\n",
    "spark.sparkContext.install_pypi_package(\"pandas==0.25.1\")\n",
    "spark.sparkContext.install_pypi_package(\"numpy==1.14.5\")\n",
    "spark.sparkContext.install_pypi_package(\"matplotlib==3.1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89816191-ea7a-4a27-acb3-500b87a7e932",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Import for typecasting columns\n",
    "from pyspark.sql.types import IntegerType,BooleanType,DateType,FloatType,StringType\n",
    "from pyspark.sql.types import ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba8f82c9-b816-4385-aa00-5931db4dd1ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defining Custom Functions (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58436bf6-8b50-4d86-b47c-3233288a38b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_quantiles(df, col_name, quantiles_list = [0.01, 0.25, 0.5, 0.75, 0.99]):\n",
    "    \"\"\"\n",
    "    Takes a numerical column and returns column values at requested quantiles\n",
    "\n",
    "    Inputs \n",
    "    Argument 1: Dataframe\n",
    "    Argument 2: Name of the column\n",
    "    Argument 3: A list of quantiles you want to find. Default value [0.01, 0.25, 0.5, 0.75, 0.99]\n",
    "\n",
    "    Output \n",
    "    Returns a dictionary with quantiles as keys and column quantile values as values \n",
    "    \"\"\"\n",
    "    # Get min, max and quantile values for given column\n",
    "    min_val = df.agg(F.min(col_name)).first()[0]\n",
    "    max_val = df.agg(F.max(col_name)).first()[0]\n",
    "    quantiles_vals = df.approxQuantile(col_name,\n",
    "                                       quantiles_list,\n",
    "                                       0)\n",
    "  \n",
    "    # Store min, quantiles and max in output dict, sequentially\n",
    "    quantiles_dict = {0.0:min_val}\n",
    "    quantiles_dict.update(dict(zip(quantiles_list, quantiles_vals)))\n",
    "    quantiles_dict.update({1.0:max_val})\n",
    "    return(quantiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "221661bd-f419-48f7-a0e6-a44974a27e11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_bucketwise_statistics (summary, bucketizer):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and a bucketizer object and plots the summary statistics for each bucket in the dataframe. \n",
    "  \n",
    "    Inputs\n",
    "    Argument 1: Pandas dataframe obtained from bucket_col_print_summary function \n",
    "    Argument 2: Bucketizer object obtained from bucket_col_print_summary function\n",
    "  \n",
    "    Output\n",
    "    Displays a plot of bucketwise average ratings nunber of ratings of a parameter.   \n",
    "    \"\"\"\n",
    "    # Creating bucket labels from splits\n",
    "    classlist = bucketizer.getSplits()\n",
    "    number_of_classes = len(classlist) - 1\n",
    "\n",
    "    class_labels = []\n",
    "    hover_labels = []\n",
    "    for i in range (number_of_classes):\n",
    "        hover_labels.append(str(classlist[i])+\"-\"+str(classlist[i+1]) +\" (Bucket name: \"+ str(int(i)) +\")\"  )\n",
    "        class_labels.append(str(classlist[i])+\"-\"+str(classlist[i+1]) )\n",
    "  \n",
    "    summary[\"Scaled_number\"] = (summary[\"n_ratings\"]-summary[\"n_ratings\"].min())/(summary[\"n_ratings\"].max()-summary[\"n_ratings\"].min()) + 1.5\n",
    "    summary['Bucket_Names'] = class_labels\n",
    "  \n",
    "    # making plot\n",
    "    x = summary[\"Bucket_Names\"]\n",
    "    y1 = summary[\"avg_rating\"]\n",
    "    y2 = summary[\"n_ratings\"]\n",
    "    err = summary[\"stddev_rating\"]  \n",
    "\n",
    "    # Plot scatter here\n",
    "    plt.rcParams[\"figure.figsize\"] = [summary.shape[0]+2, 6.0]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    bar = ax1.bar(x, y1, color = \"#0000FF\")\n",
    "    ax1.errorbar(x, y1, yerr=err, fmt=\"o\", color=\"#FF0000\")\n",
    "    ax1.set(ylim=(0, 7))\n",
    "  \n",
    "    #ax1.bar_label(bar , fmt='%.2f', label_type='edge')  \n",
    "    def barlabel(x_list,y_list):\n",
    "        for i in range(len(x_list)):\n",
    "            ax1.text(i,y_list[i] + 0.2,y_list[i], ha = 'center',\n",
    "  \t\t\t         fontdict=dict(size=10),\n",
    "  \t\t\t         bbox=dict(facecolor='#00008B', alpha=0.2)         \n",
    "  \t\t\t        )\n",
    "    barlabel(summary[\"Bucket_Names\"].tolist() ,summary[\"avg_rating\"].round(2).tolist())\n",
    "  \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.scatter(x, y2, s=summary[\"Scaled_number\"]*500, c = '#FFA500')  \n",
    "    ax2.set(ylim=(0, summary[\"n_ratings\"].max()*1.15))\n",
    "    def scatterlabel(x_list,y_list):\n",
    "  \t    for i in range(len(x_list)):\n",
    "  \t\t    ax2.text(i,y_list[i] + 15000,y_list[i], ha = 'center',\n",
    "  \t\t\t\t\t fontdict=dict(size=10),\n",
    "                     bbox=dict(facecolor='#418BFA', alpha=0.5)\n",
    "  \t\t\t\t\t)\n",
    "    scatterlabel(summary[\"Bucket_Names\"].tolist() ,summary[\"n_ratings\"].tolist())\n",
    "  \n",
    "    # giving labels to the axises\n",
    "    ax1.set_xlabel(bucketizer.getOutputCol(), fontdict=dict(size=14)) \n",
    "    ax1.set_ylabel(\"Average Ratings\",fontdict=dict(size=14))\n",
    "  \n",
    "    # secondary y-axis label\n",
    "    ax2.set_ylabel('Number of Ratings',fontdict=dict(size=14))\n",
    "  \n",
    "    #plot Title\n",
    "    plt.title('Bucketwise average ratings and number of ratings for \\n'+bucketizer.getInputCol(), \n",
    "              fontdict=dict(size=14))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f76089db-58d2-46a3-b7c2-f1c09182cd65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def bucket_col_print_summary(df, splits, inputCol, outputCol):\n",
    "    \"\"\"\n",
    "    Given a numerical column in a data frame, adds a bucketized version of the column to the data frame, according to splits provided.\n",
    "    Also prints a summary of ratings seen in each bucket made.\n",
    "\n",
    "    Inputs \n",
    "    Argument 1: Data Frame \n",
    "    Argument 2: Values at which the column will be split\n",
    "    Argument 3: Name of the input column (numerical column)\n",
    "    Argument 4: Name of the output column (bucketized numerical column)\n",
    "\n",
    "    Output: \n",
    "    1) New dataframe with the output column added\n",
    "    2) Bucketizer object trained from the input column \n",
    "    3) Pandas dataframe with summary statistics for ratings seen in buckets of the output column\n",
    "    Also plots summary statistics for ratings seen in buckets of the output column\n",
    "    \"\"\"\n",
    "\n",
    "    # Dropping bucket if it already exists\n",
    "    if outputCol in df.columns:\n",
    "        df = df.drop(outputCol)\n",
    "\n",
    "    # Training bucketizer\n",
    "    bucketizer = Bucketizer(splits = splits,\n",
    "                            inputCol  = inputCol,\n",
    "                            outputCol = outputCol)\n",
    "    \n",
    "    df = bucketizer.setHandleInvalid(\"keep\").transform(df)\n",
    "\n",
    "    # Printing meta information on buckets created\n",
    "    print(\"Added bucketized column {}\".format(outputCol))\n",
    "    print(\"\")\n",
    "    print(\"Bucketing done for split definition: {}\".format(splits))\n",
    "    print(\"\")  \n",
    "    print(\"Printing summary statistics for ratings in buckets below:\")\n",
    "\n",
    "    # Creating a summary statistics dataframe and passing it to the plotting function\n",
    "    summary =  (df\n",
    "                .groupBy(outputCol)\n",
    "                .agg(F.avg('rating').alias('avg_rating'),\n",
    "                     F.stddev('rating').alias('stddev_rating'),\n",
    "                     F.count('rating').alias('n_ratings'))\n",
    "                .sort(outputCol)\n",
    "                .toPandas())\n",
    "  \n",
    "    plot_bucketwise_statistics(summary,bucketizer)\n",
    "  \n",
    "    return df, bucketizer, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6bf27bb-3b50-49f9-989f-e3d122d5f248",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_column_distribution_summary(df, col_name):\n",
    "    \"\"\"\n",
    "    Takes a column in a data frame and prints the summary statistics (average, standard deviation, count and distinct count) for all unique values in that column.\n",
    "  \n",
    "    Inputs \n",
    "    Argument 1: Dataframe \n",
    "    Argument 2: Name of the column\n",
    "  \n",
    "    Output\n",
    "    Returns nothing \n",
    "    Prints a Dataframe with summary statistics\n",
    "    \"\"\"\n",
    "    print(df\n",
    "          .groupBy(col_name)\n",
    "          .agg(F.avg('rating').alias('avg_rating'),\n",
    "               F.stddev('rating').alias('stddev_rating'),\n",
    "               F.count('rating').alias('n_ratings'),\n",
    "               F.countDistinct('id').alias('n_recipes'))\n",
    "          .sort(F.col(col_name).asc())\n",
    "          .show(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "015aec82-c34b-4a4e-bc36-69aa74fe2fb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_n_items_satisfying_condition (df, condition, aggregation_level = \"recipe\"):\n",
    "    \"\"\"\n",
    "    Given a condition, find the number of recipes / reviews that match the condition.\n",
    "    Also calculates the percentage of such recipes / reviews as a percentage of all recipes / reviews.\n",
    "  \n",
    "    Inputs \n",
    "    Argument 1: Dataframe \n",
    "    Argument 2: Logical expression describing a condition, string type. eg: \"minutes == 0\"\n",
    "    Argument 3: Aggregation level for determining \"items\", either  \"recipe\" or \"review\". Default value == \"recipe\"\n",
    "  \n",
    "    Output: Returns no object.\n",
    "    Prints the following:\n",
    "    1) Number of recipes / reviews that satisfy the condition\n",
    "    2) Total number of recipes / reviews in the dataframe\n",
    "    3) Percentage of recipes / reviews that satisfy the condition\n",
    "    \"\"\"\n",
    "    # Find out num rows satisfying the condition\n",
    "    if aggregation_level == \"recipe\": \n",
    "        number_of_rows_satisfying_condition = (df\n",
    "                                             .filter(condition)\n",
    "                                             .agg(F.countDistinct(\"id\"))).first()[0]\n",
    "      \n",
    "        n_rows_total = (df.agg(F.countDistinct(\"id\"))).first()[0]\n",
    "    if aggregation_level == \"review\":\n",
    "        number_of_rows_satisfying_condition = (df\n",
    "                                             .filter(condition)\n",
    "                                             .agg(F.countDistinct(\"id\",\"user_id\"))).first()[0]\n",
    "        n_rows_total = (df.agg(F.countDistinct(\"id\",\"user_id\"))).first()[0]\n",
    "  \n",
    "    # Find out % rows satisfying the conditon and print a properly formatted output\n",
    "    perc_rows = round(number_of_rows_satisfying_condition * 100/ n_rows_total, 2)\n",
    "    print('Condition String                   : \"{}\"'.format(condition))\n",
    "    print(\"Number of {}s Satisfying Condition   : {} [{}%]\".format(aggregation_level.title(), number_of_rows_satisfying_condition, perc_rows))\n",
    "    print(\"Total Number of {}s                  : {}\".format(aggregation_level.title(), n_rows_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbc28dfa-055d-4596-9ae6-3a63dfb63dc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_OHE_columns (df, n_name_list):\n",
    "    \"\"\"\n",
    "    Given a list of tags, creates one hot encoded columns for each tag. \n",
    "  \n",
    "    Input\n",
    "    Argument 1: Dataframe in which the function will add the new columns\n",
    "    Argument 2: list of tags\n",
    "  \n",
    "    Output\n",
    "    Prints the names of columns that have been added \n",
    "    Returns the modified dataframe \n",
    "    \"\"\"\n",
    "    for name in n_name_list:\n",
    "        df = (df.withColumn(\"has_tag_\"+name, F.when(F.array_contains(df.tags, name), 1).otherwise(0)))\n",
    "        print (\"added column: has_tag_\"+name)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c81951e4-df1f-4ab3-a1ee-bb3bda997bb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the data (2)\n",
    "\n",
    "# Read interaction_level_df_processed\n",
    "interaction_level_df = spark.read.parquet(\"dbfs:/FileStore/interaction_level_df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f640bf1a-52ec-4589-a12d-63cd6291dc01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Adding user level average features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ea6f494-e6b6-471f-a6a7-bfb355b2e193",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "partition = Window.partitionBy(\"user_id\")\n",
    "\n",
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn(\"user_avg_rating\",\n",
    "                                    F.avg(F.col(\"rating\")).over(partition))\n",
    "                        .withColumn(\"user_n_ratings\",\n",
    "                                    F.count(F.col(\"rating\")).over(partition))\n",
    "                        .withColumn(\"user_avg_years_betwn_review_and_submission\",\n",
    "                                    F.avg(F.col(\"years_since_submission_on_review_date\")).over(partition))\n",
    "                        .withColumn(\"user_avg_prep_time_recipes_reviewed\",\n",
    "                                    F.avg(F.col(\"minutes\")).over(partition))\n",
    "                        .withColumn(\"user_avg_n_steps_recipes_reviewed\",\n",
    "                                    F.avg(F.col(\"n_steps\")).over(partition))\n",
    "                        .withColumn(\"user_avg_n_ingredients_recipes_reviewed\",\n",
    "                                    F.avg(F.col(\"n_ingredients\")).over(partition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd4e9d3a-68ca-47b9-be53-527420e47f13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nutrition_cols = ['calories',\n",
    "                  'total_fat_per_100_cal',\n",
    "                  'sugar_per_100_cal',\n",
    "                  'sodium_per_100_cal',\n",
    "                  'protein_per_100_cal',\n",
    "                  'saturated_fat_per_100_cal',\n",
    "                  'carbohydrates_per_100_cal']\n",
    "\n",
    "for nutri_col in nutrition_cols:\n",
    "    interaction_level_df = (interaction_level_df\n",
    "                            .withColumn(\"user_avg_{}_recipes_reviewed\".format(nutri_col),\n",
    "                                        F.avg(F.col(nutri_col)).over(partition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c331a53e-f2d6-4046-b8da-718386d8d55e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code. \n",
    "\n",
    "assert(round(interaction_level_df.filter('user_id == 601529').select('user_avg_rating').first()[0], 2) == 4.22)\n",
    "assert(interaction_level_df.filter('user_id == 601529').select('user_n_ratings').first()[0] == 27)\n",
    "assert(round(interaction_level_df.filter('user_id == 601529').select('user_avg_years_betwn_review_and_submission').first()[0], 2) == 3.51)\n",
    "assert(interaction_level_df.filter('user_id == 233044').select('user_avg_prep_time_recipes_reviewed').first()[0] == 50.3)\n",
    "assert(interaction_level_df.filter('user_id == 233044').select('user_avg_n_steps_recipes_reviewed').first()[0] == 8.8)\n",
    "assert(interaction_level_df.filter('user_id == 233044').select('user_avg_n_ingredients_recipes_reviewed').first()[0] == 8.2)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_total_fat_per_100_cal_recipes_reviewed').first()[0]) == 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cc830a5-b03d-433e-99f1-fbbafb7c52a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# More Features:\n",
    "# high_ratings = 5 rating\n",
    "\n",
    "# user_avg_years_betwn_review_and_submission_high_ratings\n",
    "\n",
    "# user_avg_prep_time_recipes_reviewed_high_ratings\n",
    "\n",
    "# user_avg_n_steps_recipes_reviewed_high_ratings\n",
    "\n",
    "# user_avg_n_ingredients_recipes_reviewed_high_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5a981cf-239a-415a-aeef-c0fc2f486ba6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn(\"ind_5_rating\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(1))\n",
    "                        .withColumn(\"years_since_submission_on_review_date_5_ratings\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(F.col(\"years_since_submission_on_review_date\")))\n",
    "                        .withColumn(\"minutes_5_ratings\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(F.col(\"minutes\")))\n",
    "                        .withColumn(\"n_steps_5_ratings\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(F.col(\"n_steps\")))\n",
    "                        .withColumn(\"n_ingredients_5_ratings\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(F.col(\"n_ingredients\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e45a9b9-f84f-4280-ae67-b627c7526290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "partition = Window.partitionBy(\"user_id\")\n",
    "\n",
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn(\"user_n_5_ratings\",\n",
    "                                    F.sum(F.col(\"ind_5_rating\")).over(partition))\n",
    "                        .withColumn(\"user_avg_years_betwn_review_and_submission_5_ratings\",\n",
    "                                    F.avg(F.col(\"years_since_submission_on_review_date_5_ratings\")).over(partition))\n",
    "                        .withColumn(\"user_avg_prep_time_recipes_reviewed_5_ratings\",\n",
    "                                    F.avg(F.col(\"minutes_5_ratings\")).over(partition))\n",
    "                        .withColumn(\"user_avg_n_steps_recipes_reviewed_5_ratings\",\n",
    "                                    F.avg(F.col(\"n_steps_5_ratings\")).over(partition))\n",
    "                        .withColumn(\"user_avg_n_ingredients_recipes_reviewed_5_ratings\",\n",
    "                                    F.avg(F.col(\"n_ingredients_5_ratings\")).over(partition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8a3ff2b-8e23-4f4a-b24d-eb4742d4e291",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for nutri_col in nutrition_cols:\n",
    "    interaction_level_df = (interaction_level_df\n",
    "                            .withColumn(\"{}_5_ratings\".format(nutri_col),\n",
    "                                        F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                         .otherwise(F.col(nutri_col))))\n",
    "    interaction_level_df = (interaction_level_df\n",
    "                            .withColumn(\"user_avg_{}_recipes_reviewed_5_ratings\".format(nutri_col),\n",
    "                                        F.avg(F.col(\"{}_5_ratings\".format(nutri_col))).over(partition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa14f7e7-b89f-4833-871f-d82acf507704",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check - All rows with ratings should have non-null values in corresponding user_avg_5_ratings columns\n",
    "\n",
    "assert(interaction_level_df\n",
    "       .filter(\"rating == 5\")\n",
    "       .filter(interaction_level_df.user_n_5_ratings.isNull() |\n",
    "               interaction_level_df.user_avg_years_betwn_review_and_submission_5_ratings.isNull() |\n",
    "               interaction_level_df.user_avg_prep_time_recipes_reviewed_5_ratings.isNull() |\n",
    "               interaction_level_df.user_avg_n_steps_recipes_reviewed_5_ratings.isNull() |\n",
    "               interaction_level_df.user_avg_n_ingredients_recipes_reviewed_5_ratings.isNull())\n",
    "       .count() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8db7721-3d77-436c-878c-5f24153c2974",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check values for a given user id\n",
    "\n",
    "assert(interaction_level_df.filter('user_id == 233044').select('user_n_5_ratings').first()[0] == 7)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_years_betwn_review_and_submission_5_ratings').first()[0], 2) == 2.24)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_prep_time_recipes_reviewed_5_ratings').first()[0]) == 46)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_n_steps_recipes_reviewed_5_ratings').first()[0], 2) == 7.29)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_n_ingredients_recipes_reviewed_5_ratings').first()[0], 2) == 6.86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02ce4543-f5fd-41dc-9d77-f883d95042ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ac152f1-f43b-4c43-b393-09d1935969bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 8 Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31815514-95dc-4d88-afd8-18bb836d0774",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "115e1565-e4a2-4995-baed-34d5bec2f8dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_select = [\n",
    "    \"user_n_5_ratings\",  \n",
    "    \"user_avg_prep_time_recipes_reviewed_5_ratings\", \n",
    "    \"user_avg_n_steps_recipes_reviewed_5_ratings\", \n",
    "    \"user_avg_n_ingredients_recipes_reviewed_5_ratings\"\n",
    "]\n",
    "\n",
    "# Select and display the specified columns\n",
    "interaction_level_df.select(*columns_to_select).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "403861f7-0b6f-4478-a6c6-c52771849c21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_rating_metrics = interaction_level_df.groupBy(\"user_id\").agg(\n",
    "        round(avg(\"user_avg_rating\"),2).alias(\"Average Rating\"),\n",
    "        count(\"user_n_ratings\").alias(\"Total Reviews\"),\n",
    "        count(\"ind_5_rating\").alias(\"Total of 5-star Reviews\")\n",
    "    ).orderBy(desc(\"Total Reviews\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9b13a3b-8864-487f-9111-95c78f943358",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_rating_metrics = user_rating_metrics.filter(\n",
    "    col(\"user_id\") != 424680\n",
    ")\n",
    "\n",
    "user_rating_metrics.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6291629b-02ab-4eed-b440-76c3a5062a4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtered_df = interaction_level_df.filter(interaction_level_df[\"user_avg_prep_time_recipes_reviewed\"] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0650fdb2-bff3-4008-89c7-d054cdd62d2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, round\n",
    "\n",
    "user_recipes_metrics = filtered_df.groupBy(\"user_id\").agg(\n",
    "        round(avg(\"user_avg_prep_time_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Prepared time of 5-stars\"),\n",
    "        round(avg(\"user_avg_n_steps_recipes_reviewed_5_ratings\"), 2).alias(\"Avg No. Steps of 5-stars\"),\n",
    "        round(avg(\"user_avg_n_ingredients_recipes_reviewed_5_ratings\"), 2).alias(\"Avg No. Ingredients of 5-stars\"),\n",
    "        count(\"ind_5_rating\").alias(\"Total of 5-star Reviews\")\n",
    "    ).orderBy(desc(\"Total of 5-star Reviews\"))\n",
    "    \n",
    "user_recipes_metrics = user_recipes_metrics.filter(\n",
    "    col(\"Avg Prepared time of 5-stars\") <= 300\n",
    ")\n",
    "\n",
    "# Show the result to verify\n",
    "user_recipes_metrics.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d7e2188-0b49-4540-91d8-c219fb3436c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_recipes_metrics = user_recipes_metrics.dropna(subset=[\n",
    "    \"`Avg Prepared time of 5-stars`\", \n",
    "    \"`Avg No. Steps of 5-stars`\", \n",
    "    \"`Avg No. Ingredients of 5-stars`\"\n",
    "])\n",
    "\n",
    "# Show the result to verify\n",
    "user_recipes_metrics.show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "699c735f-1c6a-4726-886a-337df840af57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_nutrition_metrics = filtered_df.groupBy(\"user_id\").agg(\n",
    "        round(avg(\"user_avg_calories_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Calories of 5-stars\"),\n",
    "        round(avg(\"user_avg_total_fat_per_100_cal_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Total Fat per 100 of 5-stars\"),\n",
    "        round(avg(\"user_avg_sugar_per_100_cal_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Sugar per 100 of 5-stars\"),\n",
    "        round(avg(\"user_avg_sodium_per_100_cal_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Sodium per 100 of 5-stars\"),\n",
    "        round(avg(\"user_avg_protein_per_100_cal_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Prorein per 100 of 5-stars\"),\n",
    "        round(avg(\"user_avg_saturated_fat_per_100_cal_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Saturated Fat per 100 of 5-stars\"),\n",
    "        round(avg(\"user_avg_carbohydrates_per_100_cal_recipes_reviewed_5_ratings\"), 2).alias(\"Avg Carbonhydrates per 100 of 5-stars\"),\n",
    "         count(\"ind_5_rating\").alias(\"Total of 5-star Reviews\")\n",
    "    ).orderBy(desc(\"Total of 5-star Reviews\"))\n",
    "\n",
    "user_nutrition_metrics = user_nutrition_metrics.dropna(subset=[\n",
    "    \"Avg Calories of 5-stars\", \n",
    "    \"Avg Total Fat per 100 of 5-stars\", \n",
    "    \"Avg Sugar per 100 of 5-stars\",\n",
    "    \"Avg Sodium per 100 of 5-stars\",\n",
    "    \"Avg Prorein per 100 of 5-stars\",\n",
    "    \"Avg Saturated Fat per 100 of 5-stars\",\n",
    "    \"Avg Carbonhydrates per 100 of 5-stars\",\n",
    "])\n",
    "\n",
    "user_nutrition_metrics = user_nutrition_metrics.filter(\n",
    "    col(\"user_id\") != 424680\n",
    ")\n",
    "\n",
    "# Show the result to verify\n",
    "user_nutrition_metrics.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa25d589-720a-4b68-b0ef-d9b42d80adb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 9: Create Tag-Level Features (Optional)\n",
    "- Analyze the tags column to identify valuable tags. Consider:\n",
    "> - Top 5 percentile of frequent tags.\n",
    "> - Top 5 percentile of highest-rated tags.\n",
    "> - Bottom 5 percentile of highest-rated tags.\n",
    "- Create features to capture information from these valuable tags.\n",
    "- Explore different encoding techniques (e.g., one-hot encoding, or more advanced methods) to represent tag information effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebad1b3f-cf04-4bfd-ae2f-98e79c39b501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Tags level EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43dbfc22-5bf1-4572-904b-ea0df8afcbce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_tag_level_df = interaction_level_df.withColumn('individual_tag',F.explode('tags'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ccc2031-514f-4897-8631-749b75d7242d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tags_ratings_summary = (interaction_tag_level_df\n",
    "                        .groupBy('individual_tag').agg(F.avg('rating').alias('avg_user_rating'),\n",
    "#                                                      F.max('rating').alias('max_user_rating'),\n",
    "#                                                      F.min('rating').alias('min_user_rating'),\n",
    "                                                       F.count('rating').alias('n_user_ratings'),\n",
    "                                                       F.countDistinct('id').alias('n_recipes')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3539bdd6-8cdf-4b4a-a22a-b669759aba07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interactions, recipes  =  interaction_level_df.count(), interaction_level_df.agg(F.countDistinct('id')).first()[0]\n",
    "\n",
    "tags_ratings_summary = (tags_ratings_summary.withColumn(\"in_percent_recipies\", F.col (\"n_recipes\")/F.lit(recipes))\n",
    "                                            .withColumn(\"in_percent_interactions\", F.col (\"n_user_ratings\")/F.lit(interactions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5db2f8c-f091-4fce-9184-3a746da63541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  b1. Top n most rated tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58b261b4-3b0e-4cc3-a242-f4fbd479ba81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tags_ratings_summary.sort(F.col(\"n_user_ratings\").desc()).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "665f8719-8597-46b7-8a9e-9fb34fc4d2ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tags_ratings_summary = tags_ratings_summary.filter(tags_ratings_summary.in_percent_interactions < 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bba0e4d-e177-4801-a39c-2903470be75c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_most_frequent_tags = tags_ratings_summary.sort(F.col(\"n_user_ratings\").desc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cb2413f-ef05-4211-9572-a6f1ab94ae03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles(df = top_most_frequent_tags , \n",
    "              col_name = 'in_percent_interactions', \n",
    "              quantiles_list = [0.01,0.25,0.5, 0.75,0.8,0.85,0.9,0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31a99463-039a-43ad-8e22-9545156a6863",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# keep tags appearing in the top 5 percentile \n",
    "top_most_frequent_tags = top_most_frequent_tags.filter(\"in_percent_interactions > 0.16\")\n",
    "\n",
    "top_most_frequent_tags.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1668742f-5872-499b-9996-df9755212f78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_frequent_tags_list = [data[0] for data in top_most_frequent_tags.select('individual_tag').collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2b1405e-1590-4967-9dad-48dad1baccf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df = add_OHE_columns (interaction_level_df, top_frequent_tags_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "821fce48-bd5f-42e5-8cd1-0e9ff06f1533",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Bottom n least rated tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "068d3e9e-58b0-49e2-82b6-f594350cf69f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tags_ratings_summary.sort(F.col(\"n_user_ratings\").asc()).show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c08517a5-14c8-4ec4-8ef9-41e7b895a6ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Cc th trn c mt trong 1 cng thc trong hn hai trm nghn. Cc tnh nng chng ti to da trn cc th ny s khng cung cp thng tin mi cho m hnh. Nu cc th ny c m ha nng, ton b ct s cha s 0 v ch mt s hng c s 1. Mt m ha nng (one hot encoding) ca cc th ny khng phi l mt  tng hay. Nu bn ngh ra mt m ha nm bt c  him ca cc th ny th ch khi  bn mi c th thm cc th ny vo phn tch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fae3b0f-a8e4-48a7-ab69-d7da3fbc49b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Top n rated tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d36361c3-8a1e-43e6-9160-c81a969a4b2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tags_ratings_summary.sort(F.col(\"avg_user_rating\").desc()).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e54ec5e0-ae3a-43ce-8c1b-9c090bf4e6c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles (tags_ratings_summary, \"n_user_ratings\", quantiles_list = [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75, 0.99])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82820d38-a65e-4ecd-a2d3-8694172f1f1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tags_ratings_summary = tags_ratings_summary.filter(tags_ratings_summary.n_user_ratings > 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01493d6c-3179-4402-9694-2eb471bfdfd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_rated_tags_df = tags_ratings_summary.sort(F.col(\"avg_user_rating\").desc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccda127f-7ae0-4750-9c89-e2ac17c2b969",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles(df = top_rated_tags_df , \n",
    "              col_name = 'avg_user_rating', \n",
    "              quantiles_list = [0.01,0.25,0.5, 0.75,0.8,0.85,0.9,0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c60ba2b-82dc-4705-aa38-974c7deb6005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# keep tags above 95 percentile\n",
    "top_rated_tags_df = top_rated_tags_df.filter(\"avg_user_rating > 4.53\")\n",
    "\n",
    "top_rated_tags_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87dd79ae-f76d-4029-ae12-76965b441c18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_rated_tags_list = [data[0] for data in top_rated_tags_df.select('individual_tag').collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "323e1f76-4feb-49b0-a844-2e5a84b1fa6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "set(top_frequent_tags_list) & set(top_rated_tags_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0f5b5e3-6d6e-4cf1-ad34-e55b92baee31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_added_columns_set = set(top_frequent_tags_list).union(set(top_rated_tags_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8506d344-d296-43b5-bc17-51d6617eb3f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df = add_OHE_columns (interaction_level_df, top_rated_tags_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d5b9df2-5de4-46ed-ae2b-4df97a454c40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_rated_tags_df.orderBy(\"avg_user_rating\", ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f459cdd-deb9-47d7-bc07-22134c22f9a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Bottom n rated tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "197980c0-ce03-4d27-892d-e4e1042e9603",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_rated_tags_df = tags_ratings_summary.sort(F.col(\"avg_user_rating\").asc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "155e2625-7ddc-4b6a-8a2f-0b4984e8e901",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_quantiles (bottom_rated_tags_df, \"avg_user_rating\", quantiles_list = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75, 0.99])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fc51901-f26a-47dc-ae22-bf238f2fda29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_rated_tags_df = bottom_rated_tags_df.filter(\"avg_user_rating < 4.00\")\n",
    "\n",
    "bottom_rated_tags_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6472bd82-6333-42cd-9ea0-0a9a7487701b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_rated_tags_list = [data[0] for data in bottom_rated_tags_df.select('individual_tag').collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f351293-797f-4846-8531-fe8e1e7b3e22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_added_columns_set & set(bottom_rated_tags_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a439614-2036-452c-9149-41d352c9cbf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df =  add_OHE_columns(interaction_level_df, bottom_rated_tags_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "578755b9-f96e-4c87-a4ad-8b7191ac8651",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_rated_tags_df.orderBy(\"avg_user_rating\", desc = True).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c502cdc-b712-4ae9-9182-bce8e8e00ab4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bottom_rated_tags_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f0f12c1-b5a7-48d2-a372-5420447c01f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Final DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59b2f0dd-adf4-40d1-ad71-42ae22994d6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(interaction_level_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06d2435a-6def-42da-9cdc-15e1b49a23cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interaction_level_df.write.mode(\"overwrite\").parquet(\"interaction_level_df_BDA\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Group 01 Assignment_Recipes Recommendation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
